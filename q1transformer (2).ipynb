{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9892159,"sourceType":"datasetVersion","datasetId":6075408}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentencepiece\n!pip install stanza","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:38:15.978036Z","iopub.execute_input":"2024-11-16T18:38:15.978351Z","iopub.status.idle":"2024-11-16T18:38:41.067485Z","shell.execute_reply.started":"2024-11-16T18:38:15.978315Z","shell.execute_reply":"2024-11-16T18:38:41.066380Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting stanza\n  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from stanza) (2.13.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stanza) (1.26.4)\nRequirement already satisfied: protobuf>=3.15.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from stanza) (2.32.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from stanza) (3.3)\nRequirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stanza) (4.66.4)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from stanza) (2.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (1.13.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (2024.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\nDownloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: stanza\nSuccessfully installed stanza-1.9.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Layer,Dense,Dropout\nimport stanza\nimport sentencepiece as spm\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:38:47.371751Z","iopub.execute_input":"2024-11-16T18:38:47.372441Z","iopub.status.idle":"2024-11-16T18:39:06.342469Z","shell.execute_reply.started":"2024-11-16T18:38:47.372402Z","shell.execute_reply":"2024-11-16T18:39:06.341691Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import re\nimport sentencepiece as spm\n\n# File paths\neng_sentences_path_q='/kaggle/input/eng-uda/quran/Quran-EN'\nurdu_sentences_path_q='/kaggle/input/eng-uda/quran/Quran-UR-normalized'\n\n\n# Function to load and clean sentences\ndef load_sentences(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n    return [line.strip() for line in lines]\n\n# Cleaning and adding tokens to English sentences\ndef clean_text_eng(text):\n    text = text.lower()\n    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove unwanted characters\n    text = re.sub(r\"\\s+\", \" \", text).strip()    # Remove extra spaces\n    return \"<start> \" + text + \" <end>\"\n\n# Cleaning, reversing, and adding tokens to Urdu sentences\ndef clean_text_urdu(text):\n    text = text.lower()\n    text = re.sub(r\"[^ء-ی\\s]\", \"\", text)       # Remove unwanted characters\n    text = re.sub(r\"\\s+\", \" \", text).strip()  # Reverse word order\n    return \"<start> \" + text + \" <end>\"\n\ndef clean_text_train_l(text):\n    text = text.lower()\n    text = re.sub(r\"[^ء-ی\\s]\", \"\", text)       # Remove unwanted characters\n    text = re.sub(r\"\\s+\", \" \", text).strip()   # Remove extra spaces\n    return \"<start> \" + text\n\n# Load and clean sentences for both languages\neng_sentences = load_sentences(eng_sentences_path_q)\nurdu_sentences = load_sentences(urdu_sentences_path_q)\n\neng_sentences = [clean_text_eng(sentence) for sentence in eng_sentences]\nurdu_sentences = [clean_text_urdu(sentence) for sentence in urdu_sentences]\nurdu_sentences_train = [clean_text_train_l(sentence) for sentence in urdu_sentences]\n\n\n# Ensure both files have the same number of lines\nassert len(eng_sentences) == len(urdu_sentences), \"Mismatch in number of sentences.\"\n\n# Save cleaned sentences to text files\nwith open(\"eng_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(eng_sentences))\n\nwith open(\"urdu_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(urdu_sentences))\n\n# Function to calculate dynamic vocabulary size\ndef calculate_vocab_size(sentences):\n    all_tokens = set(token for sentence in sentences for token in sentence.split())\n    return int(len(all_tokens) * 1.1)  # Add 10% buffer for unseen tokens\n\n# Calculate vocabulary sizes\neng_vocab_size = calculate_vocab_size(eng_sentences)\nurdu_vocab_size = calculate_vocab_size(urdu_sentences)\n\nprint(f\"Dynamic English vocab size: {eng_vocab_size}\")\nprint(f\"Dynamic Urdu vocab size: {urdu_vocab_size}\")\n\n# Train BPE models with special tokens\nspm.SentencePieceTrainer.train(\n    input=\"eng_sentences.txt\",\n    model_prefix=\"eng_bpe\",\n    vocab_size=eng_vocab_size,\n    model_type=\"bpe\",\n    unk_piece=\"<unk>\",\n    user_defined_symbols=[\"<start>\", \"<end>\"]\n)\n\n\nspm.SentencePieceTrainer.train(\n    input=\"urdu_sentences.txt\",\n    model_prefix=\"urdu_bpe\",\n    vocab_size=urdu_vocab_size,\n    model_type=\"bpe\",\n    unk_piece=\"<unk>\",\n    user_defined_symbols=[\"<start>\", \"<end>\"]\n)\n\n# Load trained SentencePiece models\nsp_eng = spm.SentencePieceProcessor(model_file=\"eng_bpe.model\")\nsp_urdu = spm.SentencePieceProcessor(model_file=\"urdu_bpe.model\")\n\n# Example tokenization\nsample_eng = \"<start> This is a test sentence. <end>\"\nsample_urdu = \"<start> یہ ایک آزمائشی جملہ ہے۔ <end>\"\n\nprint(\"English tokens:\", sp_eng.encode(sample_eng, out_type=str))\nprint(\"Urdu tokens:\", sp_urdu.encode(sample_urdu, out_type=str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:29.192125Z","iopub.execute_input":"2024-11-16T18:40:29.192788Z","iopub.status.idle":"2024-11-16T18:40:31.249858Z","shell.execute_reply.started":"2024-11-16T18:40:29.192745Z","shell.execute_reply":"2024-11-16T18:40:31.248690Z"}},"outputs":[{"name":"stdout","text":"Dynamic English vocab size: 8933\nDynamic Urdu vocab size: 7771\nEnglish tokens: ['▁', '<start>', '▁', 'T', 'hi', 's', '▁is', '▁a', '▁test', '▁sentence', '.', '▁', '<end>']\nUrdu tokens: ['▁', '<start>', '▁یہ', '▁ایک', '▁آزمائ', 'شی', '▁جملہ', '▁ہ', 'ے۔', '▁', '<end>']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def tokens_to_ids_urd(tokens):\n    return [sp_urdu.piece_to_id(token) for token in tokens]\n\ndef tokens_to_ids_eng(tokens):\n    return [sp_eng.piece_to_id(token) for token in tokens]\n    \ndef process_sentences(src_sentences, target_sentences, max_tokens):\n    src_tokenized = [sp_eng.encode_as_pieces(eng) for eng in src_sentences]  # English (source)\n    target_tokenized = [sp_urdu.encode_as_pieces(urdu) for urdu in target_sentences]  # Urdu (target)\n    src_ids = [tokens_to_ids_eng(sentence) for sentence in src_tokenized]\n    target_ids = [tokens_to_ids_urd(sentence) for sentence in target_tokenized]\n    src_ragged = tf.ragged.constant(src_ids, dtype=tf.int32)\n    target_ragged = tf.ragged.constant(target_ids, dtype=tf.int32)\n    src_ragged = src_ragged[:, :max_tokens]\n    target_ragged = target_ragged[:, :max_tokens]\n    inputs = src_ragged\n    labels = target_ragged\n\n    # Pad sequences to ensure they are of the same length\n    inputs_padded = inputs.to_tensor(default_value=0, shape=[None, max_tokens])\n    labels_padded = labels.to_tensor(default_value=0, shape=[None, max_tokens])\n    return inputs_padded,labels_padded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:34.501147Z","iopub.execute_input":"2024-11-16T18:40:34.501984Z","iopub.status.idle":"2024-11-16T18:40:34.510269Z","shell.execute_reply.started":"2024-11-16T18:40:34.501948Z","shell.execute_reply":"2024-11-16T18:40:34.509253Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"max_tokens = 100  # You can adjust the max number of tokens based on your requirements\n\ninputs, labels = process_sentences(eng_sentences, urdu_sentences, max_tokens)\ninputsxx, labels_train = process_sentences(eng_sentences, urdu_sentences_train, max_tokens) #for this i will only use labels_train as it has no <end> tag while labels has <end> tag\n\nprint(inputs[0])\nprint(labels_train[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:35.474413Z","iopub.execute_input":"2024-11-16T18:40:35.475088Z","iopub.status.idle":"2024-11-16T18:40:43.031686Z","shell.execute_reply.started":"2024-11-16T18:40:35.475050Z","shell.execute_reply":"2024-11-16T18:40:43.030755Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[8907    3   40 1042   39   35   56  317    8 2326   28   40    8 1136\n 8907    4    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0], shape=(100,), dtype=int32)\ntf.Tensor(\n[7730    3  152 1688   59   88    6   73   42   52  505 1003   20 2240\n  361  112    7    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0], shape=(100,), dtype=int32)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(len(labels))\nprint(len(labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:46.036504Z","iopub.execute_input":"2024-11-16T18:40:46.036931Z","iopub.status.idle":"2024-11-16T18:40:46.042191Z","shell.execute_reply.started":"2024-11-16T18:40:46.036894Z","shell.execute_reply":"2024-11-16T18:40:46.041217Z"}},"outputs":[{"name":"stdout","text":"6414\n6414\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def detokenize_with_masking_urdu(tokens):\n    # Remove padding tokens (assuming padding token is 0)\n    tokens = [token for token in tokens if token != 0]\n    return sp_urdu.decode_ids(tokens)\ndef detokenize_with_masking_eng(tokens):\n    # Remove padding tokens (assuming padding token is 0)\n    tokens = [token for token in tokens if token != 0]\n    return sp_eng.decode_ids(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:47.990375Z","iopub.execute_input":"2024-11-16T18:40:47.991249Z","iopub.status.idle":"2024-11-16T18:40:47.996309Z","shell.execute_reply.started":"2024-11-16T18:40:47.991207Z","shell.execute_reply":"2024-11-16T18:40:47.995428Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"detokenized_input = detokenize_with_masking_eng(inputs[0].numpy().tolist())\ndetokenized_label = detokenize_with_masking_urdu(labels[0].numpy().tolist())\n\nprint(labels[0])\n\nprint(\"Detokenized Input (English):\", detokenized_input)\nprint(\"Detokenized Label (Urdu):\", detokenized_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:49.055591Z","iopub.execute_input":"2024-11-16T18:40:49.055999Z","iopub.status.idle":"2024-11-16T18:40:49.065316Z","shell.execute_reply.started":"2024-11-16T18:40:49.055959Z","shell.execute_reply":"2024-11-16T18:40:49.064409Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[7730    3  152 1688   59   88    6   73   42   52  505 1003   20 2240\n  361  112    7 7730    4    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0], shape=(100,), dtype=int32)\nDetokenized Input (English): <start> all praise be to allah alone the sustainer of all the worlds <end>\nDetokenized Label (Urdu): <start> سب تعریفیں اللہ ہی ک لئ ہیں جو تمام جہانوں کی پرورش فرمان والا ہ <end>\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Ensure inputs are correctly structured as arrays\ninputs_0 = inputs.numpy()  # Convert to numpy arrays\ninputs_1 = labels_train.numpy()  # Convert to numpy arrays\n\n# Split the data into training and validation sets (split inputs and labels separately)\ntrain_inputs_0, val_inputs_0, train_inputs_1, val_inputs_1, train_labels, val_labels = train_test_split(\n    inputs_0, inputs_1, labels.numpy(), test_size=0.1, random_state=42\n)\n\n# Ensure train_labels and val_labels have the correct shape\ntrain_labels = tf.reshape(train_labels, (train_labels.shape[0], -1))  # Reshape to [batch_size, label_dim]\nval_labels = tf.reshape(val_labels, (val_labels.shape[0], -1))\n\n# Create the training dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\n    ((train_inputs_0, train_inputs_1), train_labels)  # Unpack the tuple properly for multiple inputs\n)\n\n# Create the validation dataset\nval_dataset = tf.data.Dataset.from_tensor_slices(\n    ((val_inputs_0, val_inputs_1), val_labels)  # Unpack the tuple properly for multiple inputs\n)\n\n# Shuffle and batch the training data\ntrain_dataset = train_dataset.shuffle(buffer_size=10000).batch(32, drop_remainder=True)\n\n# Batch the validation data without shuffling\nval_dataset = val_dataset.batch(32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:50.816962Z","iopub.execute_input":"2024-11-16T18:40:50.817863Z","iopub.status.idle":"2024-11-16T18:40:50.862291Z","shell.execute_reply.started":"2024-11-16T18:40:50.817803Z","shell.execute_reply":"2024-11-16T18:40:50.861534Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\nfor data, label in train_dataset.take(1):  # Take one batch\n    print(\"Data (inputs):\", data)\n    print(\"Label:\", label)\n    print(\"x shape:\", data[0].shape)  # First input (x)\n    print(\"y shape:\", data[1].shape)  # Second input (y)\n    print(\"Label shape:\", label.shape)  # Label shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:51.429056Z","iopub.execute_input":"2024-11-16T18:40:51.429419Z","iopub.status.idle":"2024-11-16T18:40:51.492415Z","shell.execute_reply.started":"2024-11-16T18:40:51.429385Z","shell.execute_reply":"2024-11-16T18:40:51.491473Z"}},"outputs":[{"name":"stdout","text":"Data (inputs): (<tf.Tensor: shape=(32, 100), dtype=int32, numpy=\narray([[8907,    3,   50, ...,    0,    0,    0],\n       [8907,    3, 1060, ...,    0,    0,    0],\n       [8907,    3,   31, ...,    0,    0,    0],\n       ...,\n       [8907,    3,   89, ...,  523,  310,   50],\n       [8907,    3,   15, ...,    0,    0,    0],\n       [8907,    3, 2234, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(32, 100), dtype=int32, numpy=\narray([[7730,    3,  255, ...,    0,    0,    0],\n       [7730,    3,  503, ...,    0,    0,    0],\n       [7730,    3,   32, ...,    0,    0,    0],\n       ...,\n       [7730,    3,  340, ...,  105,  205, 1838],\n       [7730,    3,   15, ...,    0,    0,    0],\n       [7730,    3, 1226, ...,    0,    0,    0]], dtype=int32)>)\nLabel: tf.Tensor(\n[[7730    3  255 ...    0    0    0]\n [7730    3  503 ...    0    0    0]\n [7730    3   32 ...    0    0    0]\n ...\n [7730    3  340 ...  105  205 1838]\n [7730    3   15 ...    0    0    0]\n [7730    3 1226 ...    0    0    0]], shape=(32, 100), dtype=int32)\nx shape: (32, 100)\ny shape: (32, 100)\nLabel shape: (32, 100)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def positional_encoding(position, d_model):\n    angle_rads = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model) // 2)) / np.float32(d_model))\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n    return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:52.222599Z","iopub.execute_input":"2024-11-16T18:40:52.222986Z","iopub.status.idle":"2024-11-16T18:40:52.229613Z","shell.execute_reply.started":"2024-11-16T18:40:52.222950Z","shell.execute_reply":"2024-11-16T18:40:52.228585Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"**Maksanknjasdn**","metadata":{}},{"cell_type":"code","source":"def get_positional_encoding(seq_len, model_dim):\n    pos = np.arange(seq_len)[:, np.newaxis]\n    i = np.arange(model_dim)[np.newaxis, :]\n    \n    angle_rads = pos / np.power(10000, (2 * (i // 2)) / np.float32(model_dim))\n    \n    # Apply sin to even indices in the array; 2i\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    \n    # Apply cos to odd indices in the array; 2i+1\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n    \n    pos_encoding = angle_rads[np.newaxis, ...]\n    \n    return tf.cast(pos_encoding, dtype=tf.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:53.167593Z","iopub.execute_input":"2024-11-16T18:40:53.168692Z","iopub.status.idle":"2024-11-16T18:40:53.176427Z","shell.execute_reply.started":"2024-11-16T18:40:53.168640Z","shell.execute_reply":"2024-11-16T18:40:53.175281Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class Pos_emb(Layer):\n    def __init__(self,v_s,dim):\n        super().__init__()\n        self.embedding=tf.keras.layers.Embedding(v_s,dim,mask_zero=True)\n        self.pos_encoding=get_positional_encoding(100,dim)\n\n    def call(self,input):\n        temp=self.embedding(input)\n        seq_len=tf.shape(input)[1]\n        temp=temp+self.pos_encoding[:seq_len,:]\n        return temp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:53.575171Z","iopub.execute_input":"2024-11-16T18:40:53.575744Z","iopub.status.idle":"2024-11-16T18:40:53.582224Z","shell.execute_reply.started":"2024-11-16T18:40:53.575700Z","shell.execute_reply":"2024-11-16T18:40:53.581208Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class MultiHeadAttention(Layer):\n    def __init__(self, num_heads, d_model):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n        \n        assert d_model % self.num_heads == 0, \"d_model must be divisible by num_heads\"\n\n        # Depth of each attention head\n        self.depth = d_model // self.num_heads\n\n        # Separate weight matrices for Q, K, V with L2 regularization\n        self.wq = Dense(d_model, kernel_regularizer=tf.keras.regularizers.l2(0.0001))  # L2 Regularization\n        self.wk = Dense(d_model, kernel_regularizer=tf.keras.regularizers.l2(0.0001))  # L2 Regularization\n        self.wv = Dense(d_model, kernel_regularizer=tf.keras.regularizers.l2(0.0001))  # L2 Regularization\n\n        # Final dense layer to output\n        self.dense = Dense(d_model, kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n\n    def split_heads(self, x, batch_size):\n        \"\"\" Split the last dimension into (num_heads, depth).\"\"\"\n        # x.shape -> (batch_size, seq_len, d_model)\n        # return shape -> (batch_size, num_heads, seq_len, depth)\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, depth)\n\n    def attention(self, q, k, v, mask=None):\n        \"\"\" Scaled Dot-Product Attention \"\"\"\n        matmul_qk = tf.matmul(q, k, transpose_b=True)  # (batch_size, num_heads, seq_len, seq_len)\n        \n        # Scale by the square root of depth\n        d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n        scaled_attention_logits = matmul_qk / tf.math.sqrt(d_k)\n\n        # Masking (optional)\n        if mask is not None:\n            scaled_attention_logits += (mask * -1e9)\n\n        # Attention weights\n        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (batch_size, num_heads, seq_len, seq_len)\n\n        # Output\n        output = tf.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len, depth)\n        return output, attention_weights\n\n    def call(self, query, key, value, mask=None):\n        batch_size = tf.shape(query)[0]\n\n        # Linear projections for Q, K, V\n        q = self.wq(query)  # (batch_size, seq_len_q, d_model)\n        k = self.wk(key)    # (batch_size, seq_len_k, d_model)\n        v = self.wv(value)  # (batch_size, seq_len_v, d_model)\n\n        # Split into multiple heads\n        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n\n        # Apply attention\n        output, attention_weights = self.attention(q, k, v, mask)\n\n        # Concatenate heads\n        output = tf.transpose(output, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n        output = tf.reshape(output, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n\n        # Final linear projection\n        output = self.dense(output)  # (batch_size, seq_len_q, d_model)\n\n        return output, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:53.970246Z","iopub.execute_input":"2024-11-16T18:40:53.970666Z","iopub.status.idle":"2024-11-16T18:40:53.985634Z","shell.execute_reply.started":"2024-11-16T18:40:53.970627Z","shell.execute_reply":"2024-11-16T18:40:53.984709Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class Attention(Layer):\n    def __init__(self, num_heads, dim):\n        super().__init__()\n        # Initialize the custom MultiHeadAttention layer and other components\n        self.multi_base = MultiHeadAttention(num_heads, dim)\n        self.norm_ = tf.keras.layers.LayerNormalization()\n        self.add_ = tf.keras.layers.Add()\n\n    def call(self, query, input, mask=None):\n        # Perform the multi-head attention\n        attention_out, _ = self.multi_base(query=query, key=input, value=input, mask=mask)\n        # Add the input and attention output, followed by normalization\n        temp = self.add_([input, attention_out])\n        return self.norm_(temp)\n\nclass CrossAttention(Attention):\n    def __init__(self, **kwargs):\n        # Call the parent class initializer\n        super().__init__(**kwargs)\n\n    def call(self, query, input):\n        # Perform the multi-head attention\n        attention_out, _ = self.multi_base(query=query, key=input, value=input,mask=None)\n        # Add the input and attention output, followed by normalization\n        temp = self.add_([input, attention_out])\n        return self.norm_(temp)\nclass SelfAttention(Attention):\n    def __init__(self, **kwargs):\n        # Call the parent class initializer\n        super().__init__(**kwargs)\n\n    def call(self, input):\n        # Perform the multi-head attention\n        attention_out, _ = self.multi_base(query=input, key=input, value=input,mask=None)\n        # Add the input and attention output, followed by normalization\n        temp = self.add_([input, attention_out])\n        return self.norm_(temp)\nclass MaskedAttention(Attention):\n    def __init__(self, use_causal_mask=False, **kwargs):\n        # Call the parent class initializer\n        super().__init__(**kwargs)\n        self.use_causal_mask = use_causal_mask\n\n    def create_causal_mask(self, size):\n        \"\"\" Create a causal mask to prevent attending to future positions. \"\"\"\n        mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n        return mask  # (seq_len, seq_len)\n\n    def call(self, input):\n        seq_len = tf.shape(input)[1]  # Assuming query and input have the same length\n        mask = None\n        \n        # Generate causal mask if required\n        if self.use_causal_mask:\n            mask = self.create_causal_mask(seq_len)\n            mask = mask[tf.newaxis, tf.newaxis, :, :]  # Add batch and head dimensions\n\n        # Perform the multi-head attention with optional mask\n        attention_out, _ = self.multi_base(query=input, key=input, value=input, mask=mask)\n\n        # Add the input and attention output, followed by normalization\n        temp = self.add_([input, attention_out])\n        return self.norm_(temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:54.446031Z","iopub.execute_input":"2024-11-16T18:40:54.446422Z","iopub.status.idle":"2024-11-16T18:40:54.460946Z","shell.execute_reply.started":"2024-11-16T18:40:54.446384Z","shell.execute_reply":"2024-11-16T18:40:54.459996Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class FeedForward(Layer):\n    def __init__(self,drate):\n        super().__init__()\n        self.ffn=tf.keras.Sequential([\n            tf.keras.layers.Dense(128,activation='relu'),\n            tf.keras.layers.Dense(512)\n        ])\n        self.add_=tf.keras.layers.Add()\n        self.norm_=tf.keras.layers.LayerNormalization()\n    def call(self,input):\n        temp = self.add_([input, self.ffn(input)])\n        return self.norm_(temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:54.782688Z","iopub.execute_input":"2024-11-16T18:40:54.783077Z","iopub.status.idle":"2024-11-16T18:40:54.789868Z","shell.execute_reply.started":"2024-11-16T18:40:54.783039Z","shell.execute_reply":"2024-11-16T18:40:54.788827Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class Encoder_layer(Layer):\n    def __init__(self, dim, num_head, drate=0.3):  # Increased dropout rate\n        super().__init__()\n        self.attention = SelfAttention(num_heads=num_head, dim=dim)\n        self.ffn = FeedForward(drate)\n        self.dropout = tf.keras.layers.Dropout(drate)  # Increase dropout\n    def call(self, input):\n        temp = self.attention(input)\n        temp = self.dropout(temp)  # Apply dropout after attention\n        temp = self.ffn(temp)\n        return temp\n\nclass Encoder_(Layer):\n    def __init__(self, dim, num_head, drate=0.3):\n        super().__init__()\n        # Positional Encoding Layer\n        self.pos_emb = Pos_emb(v_s=eng_vocab_size, dim=dim)\n        # Encoder layers\n        self.encoder_l = [Encoder_layer(dim=dim, num_head=num_head, drate=drate) for _ in range(6)]\n\n    def call(self, input, mask=None):\n        # Apply positional encoding to the input\n        temp = self.pos_emb(input)\n        # Pass through each encoder layer\n        for layer in range(6):\n            temp = self.encoder_l[layer](temp)\n        return temp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:55.429637Z","iopub.execute_input":"2024-11-16T18:40:55.430501Z","iopub.status.idle":"2024-11-16T18:40:55.439226Z","shell.execute_reply.started":"2024-11-16T18:40:55.430458Z","shell.execute_reply":"2024-11-16T18:40:55.438308Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class Decoder_layer(Layer):\n    def __init__(self, dim, num_head, drate=0.3):  # Increased dropout rate\n        super().__init__()\n        self.masked_att = MaskedAttention(num_heads=num_head, dim=dim)\n        self.cross_att = CrossAttention(num_heads=num_head, dim=dim)\n        self.ffn = FeedForward(drate)\n        self.add_ = tf.keras.layers.Add()\n\n    def call(self, input, encoder):\n        temp = self.masked_att(input)\n        temp = self.cross_att(temp, encoder)\n        temp = self.ffn(temp)\n        temp = self.add_([temp, temp])  # Add skip connection\n        return temp\n        \nclass Decoder_(Layer):\n    def __init__(self, dim, num_head, drate=0.3):\n        super().__init__()\n        self.pos_emb_ur = Pos_emb(v_s=urdu_vocab_size, dim=dim)\n        # Encoder layers\n        self.decoder_l = [Decoder_layer(dim=dim, num_head=num_head, drate=drate) for _ in range(6)]\n\n    def call(self, input,encoder, mask=None):\n        # Apply positional encoding to the input\n        temp = self.pos_emb_ur(input)\n        # Pass through each encoder layer\n        for layer in range(6):\n            temp = self.decoder_l[layer](temp,encoder)\n        return temp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:55.629986Z","iopub.execute_input":"2024-11-16T18:40:55.630396Z","iopub.status.idle":"2024-11-16T18:40:55.640212Z","shell.execute_reply.started":"2024-11-16T18:40:55.630357Z","shell.execute_reply":"2024-11-16T18:40:55.639099Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import tensorflow as tf\n\n# Define Encoder\nencoder_input = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"ei\")\nencoder_o = Encoder_(512, 4)(encoder_input)  # Encoder output\nencoder=tf.keras.Model(encoder_input,encoder_o)\nencoder.summary()\n\n# Define Decoder\ndecoder_input = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"di\")\ndecoder_o = Decoder_(512, 4)(decoder_input, encoder_o)  # Decoder output using encoder_o\n\ndense_output = tf.keras.layers.Dense(urdu_vocab_size)(decoder_o)\nsoftmax_output = tf.keras.layers.Softmax(axis=-1)(dense_output)\n\n# Define the full model\ndecoder_model = tf.keras.Model([encoder_input, decoder_input], softmax_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:40:56.076547Z","iopub.execute_input":"2024-11-16T18:40:56.076932Z","iopub.status.idle":"2024-11-16T18:41:03.622417Z","shell.execute_reply.started":"2024-11-16T18:40:56.076895Z","shell.execute_reply":"2024-11-16T18:41:03.621603Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ ei (\u001b[38;5;33mInputLayer\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_ (\u001b[38;5;33mEncoder_\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m11,680,000\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ ei (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ encoder_ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,680,000</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,680,000\u001b[0m (44.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,680,000</span> (44.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,680,000\u001b[0m (44.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,680,000</span> (44.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"transformer=tf.keras.Model([encoder_input,decoder_input],softmax_output,name=\"transformer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:41:03.624097Z","iopub.execute_input":"2024-11-16T18:41:03.624884Z","iopub.status.idle":"2024-11-16T18:41:03.632158Z","shell.execute_reply.started":"2024-11-16T18:41:03.624838Z","shell.execute_reply":"2024-11-16T18:41:03.631379Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"transformer.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:41:06.547320Z","iopub.execute_input":"2024-11-16T18:41:06.548024Z","iopub.status.idle":"2024-11-16T18:41:06.579571Z","shell.execute_reply.started":"2024-11-16T18:41:06.547984Z","shell.execute_reply":"2024-11-16T18:41:06.578708Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ ei (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ di (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_ (\u001b[38;5;33mEncoder_\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │ \u001b[38;5;34m11,680,000\u001b[0m │ ei[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_ (\u001b[38;5;33mDecoder_\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │ \u001b[38;5;34m17,394,944\u001b[0m │ di[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                     │                   │            │ encoder_[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_96 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7771\u001b[0m) │  \u001b[38;5;34m3,986,523\u001b[0m │ decoder_[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7771\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ ei (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ di (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ encoder_ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">11,680,000</span> │ ei[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder_</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">17,394,944</span> │ di[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                     │                   │            │ encoder_[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7771</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,986,523</span> │ decoder_[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7771</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,061,467\u001b[0m (126.12 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,061,467</span> (126.12 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,061,467\u001b[0m (126.12 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,061,467</span> (126.12 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, d_model, warmup_steps=1000):\n        super().__init__()\n        self.d_model = d_model\n        self.d_model = tf.cast(self.d_model, tf.float32)\n        self.warmup_steps = warmup_steps\n\n    def __call__(self, step):\n        step = tf.cast(step, dtype=tf.float32)\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps ** -1.5)\n\n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n\n    def get_config(self):\n        return {\n            \"d_model\": self.d_model.numpy(),  # Ensure it's converted to a serializable value\n            \"warmup_steps\": self.warmup_steps,\n        }\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\nlearning_rate = CustomSchedule(512)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.09, beta_2=0.098,\n                                     epsilon=1e-4)\n\ndef masked_loss(label, pred):\n\n  print(label)\n  print(pred)\n  mask = label != 0\n  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n  loss = loss_object(label, pred)\n\n  mask = tf.cast(mask, dtype=loss.dtype)\n  loss *= mask\n\n  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n  return loss\n\n\ndef masked_accuracy(label, pred):\n  pred = tf.argmax(pred, axis=2)\n  label = tf.cast(label, pred.dtype)\n  match = label == pred\n\n  mask = label != 0\n\n  match = match & mask\n\n  match = tf.cast(match, dtype=tf.float32)\n  mask = tf.cast(mask, dtype=tf.float32)\n  return tf.reduce_sum(match)/tf.reduce_sum(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:41:08.301283Z","iopub.execute_input":"2024-11-16T18:41:08.301679Z","iopub.status.idle":"2024-11-16T18:41:08.319537Z","shell.execute_reply.started":"2024-11-16T18:41:08.301640Z","shell.execute_reply":"2024-11-16T18:41:08.318521Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"transformer.compile(\n    loss=masked_loss,\n    optimizer=optimizer,\n    metrics=[masked_accuracy])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:41:08.810736Z","iopub.execute_input":"2024-11-16T18:41:08.811579Z","iopub.status.idle":"2024-11-16T18:41:08.821235Z","shell.execute_reply.started":"2024-11-16T18:41:08.811537Z","shell.execute_reply":"2024-11-16T18:41:08.820438Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"history=transformer.fit(train_dataset,epochs=20,validation_data=val_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T19:19:27.953754Z","iopub.execute_input":"2024-11-16T19:19:27.954851Z","iopub.status.idle":"2024-11-16T19:26:49.585663Z","shell.execute_reply.started":"2024-11-16T19:19:27.954790Z","shell.execute_reply":"2024-11-16T19:26:49.584832Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.1307 - masked_accuracy: 0.1521 - val_loss: 5.5260 - val_masked_accuracy: 0.1423\nEpoch 2/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.1258 - masked_accuracy: 0.1529 - val_loss: 5.5269 - val_masked_accuracy: 0.1399\nEpoch 3/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.1149 - masked_accuracy: 0.1532 - val_loss: 5.5372 - val_masked_accuracy: 0.1387\nEpoch 4/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.1174 - masked_accuracy: 0.1541 - val_loss: 5.5232 - val_masked_accuracy: 0.1427\nEpoch 5/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.1205 - masked_accuracy: 0.1523 - val_loss: 5.5246 - val_masked_accuracy: 0.1391\nEpoch 6/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.1092 - masked_accuracy: 0.1532 - val_loss: 5.5190 - val_masked_accuracy: 0.1413\nEpoch 7/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0967 - masked_accuracy: 0.1530 - val_loss: 5.5365 - val_masked_accuracy: 0.1430\nEpoch 8/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0931 - masked_accuracy: 0.1548 - val_loss: 5.5206 - val_masked_accuracy: 0.1397\nEpoch 9/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0793 - masked_accuracy: 0.1566 - val_loss: 5.5134 - val_masked_accuracy: 0.1439\nEpoch 10/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0930 - masked_accuracy: 0.1527 - val_loss: 5.5166 - val_masked_accuracy: 0.1421\nEpoch 11/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0762 - masked_accuracy: 0.1551 - val_loss: 5.5133 - val_masked_accuracy: 0.1415\nEpoch 12/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0921 - masked_accuracy: 0.1538 - val_loss: 5.5122 - val_masked_accuracy: 0.1429\nEpoch 13/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0571 - masked_accuracy: 0.1557 - val_loss: 5.5250 - val_masked_accuracy: 0.1435\nEpoch 14/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0658 - masked_accuracy: 0.1554 - val_loss: 5.5088 - val_masked_accuracy: 0.1413\nEpoch 15/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0415 - masked_accuracy: 0.1579 - val_loss: 5.4987 - val_masked_accuracy: 0.1442\nEpoch 16/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0609 - masked_accuracy: 0.1556 - val_loss: 5.5114 - val_masked_accuracy: 0.1424\nEpoch 17/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0475 - masked_accuracy: 0.1549 - val_loss: 5.5023 - val_masked_accuracy: 0.1452\nEpoch 18/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0450 - masked_accuracy: 0.1563 - val_loss: 5.5019 - val_masked_accuracy: 0.1456\nEpoch 19/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0465 - masked_accuracy: 0.1575 - val_loss: 5.5087 - val_masked_accuracy: 0.1453\nEpoch 20/20\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0352 - masked_accuracy: 0.1563 - val_loss: 5.5061 - val_masked_accuracy: 0.1441\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\ndef translate_sentence(input_sentence, \n                       input_sp_model, \n                       target_sp_model, \n                       translation_model, \n                       max_length=50):\n    # Tokenize and encode the input sentence\n    input_sentence=clean_text_eng(input_sentence)\n    input_tokens = input_sp_model.encode(input_sentence, out_type=int)\n    \n    # Add batch and pad to max_length\n    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n        [input_tokens], maxlen=max_length, padding=\"post\"\n    )\n\n    print(\"Input tensor:\", input_tensor)\n    \n    # Prepare initial target sequence with the <start> token\n    target_start_token = target_sp_model.piece_to_id(\"<start>\")\n    target_end_token = target_sp_model.piece_to_id(\"<end>\")\n    target_sequence = [target_start_token]\n    \n    # Begin translation\n    for _ in range(max_length):\n        # Pad the target sequence\n        target_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n            [target_sequence], maxlen=max_length, padding=\"post\"\n        )\n        \n        # Predict the next token\n        predictions = translation_model.predict([input_tensor, target_tensor], verbose=0)\n        next_token = np.argmax(predictions[0, len(target_sequence) - 1])\n        \n        # Append the predicted token to the target sequence\n        target_sequence.append(next_token)\n        \n        # Stop if the end token is predicted\n        if next_token == target_end_token:\n            break\n    \n    # Decode the sequence back to a sentence\n    target_sequence=target_sequence[::-1]\n    translated_tokens = list(map(int, target_sequence))  # Convert to plain integers and exclude <start>/<end>\n    print(\"Translated tokens:\", translated_tokens)\n    translated_sentence = target_sp_model.decode(translated_tokens)\n    \n    return translated_sentence\n\n# Example usage\nsample_eng_sentence = \"Allah is all Knowing\"\nsample_eng_sentence = \"<start> \" + sample_eng_sentence + \" <end>\"\n\ntranslated_to_urdu = translate_sentence(\n    input_sentence=sample_eng_sentence,\n    input_sp_model=sp_eng,\n    target_sp_model=sp_urdu,\n    translation_model=transformer,\n    max_length=100\n)\n\nprint(translated_to_urdu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T19:26:56.240705Z","iopub.execute_input":"2024-11-16T19:26:56.241643Z","iopub.status.idle":"2024-11-16T19:26:56.980976Z","shell.execute_reply.started":"2024-11-16T19:26:56.241601Z","shell.execute_reply":"2024-11-16T19:26:56.979992Z"}},"outputs":[{"name":"stdout","text":"Input tensor: [[8907    3 1420   56   51   40  753  778 8907    4    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7, 7, 7, 59, 72, 59, 5, 3, 7730, 3]\n<end>  ہ ہ ہ اللہ لوگ اللہ ا<start> <start>\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"transformer.save('transformer_new_20.h5')\ntransformer.save('transformer_new_20.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T19:27:15.469965Z","iopub.execute_input":"2024-11-16T19:27:15.470371Z","iopub.status.idle":"2024-11-16T19:27:18.410864Z","shell.execute_reply.started":"2024-11-16T19:27:15.470334Z","shell.execute_reply":"2024-11-16T19:27:18.409835Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:58:38.397576Z","iopub.execute_input":"2024-11-16T16:58:38.398277Z","iopub.status.idle":"2024-11-16T16:58:50.332724Z","shell.execute_reply.started":"2024-11-16T16:58:38.398236Z","shell.execute_reply":"2024-11-16T16:58:50.331485Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\ndef evaluate_translation(model, inputs, labels, input_sp_model, target_sp_model, max_length):\n    total_bleu = 0\n    total_rouge = 0\n    \n    # Initialize ROUGE scorer with desired metrics\n    rouge_scorer_instance = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    \n    # Iterate over the inputs and evaluate translation for each sentence\n    for i in range(len(inputs)):\n        # Ensure that the input is a list before decoding\n        input_sentence = input_sp_model.decode(inputs[i].tolist())  # Convert numpy array to list\n        true_output = target_sp_model.decode(labels[i].tolist())  # Convert numpy array to list\n\n        # Translate the sentence using the model\n        translated_sentence = translate_sentence(\n            input_sentence=input_sentence,\n            input_sp_model=input_sp_model,\n            target_sp_model=target_sp_model,\n            translation_model=model,\n            max_length=max_length\n        )\n        \n        # Compute BLEU score\n        bleu_score = sentence_bleu([true_output.split()], translated_sentence.split())\n\n        # Compute ROUGE score\n        rouge_score = rouge_scorer_instance.score(true_output, translated_sentence)['rougeL'].fmeasure\n\n        total_bleu += bleu_score\n        total_rouge += rouge_score\n\n    avg_bleu = total_bleu / len(inputs)\n    avg_rouge = total_rouge / len(inputs)\n\n    return avg_bleu, avg_rouge\n\n# Now, you can call the evaluate_translation function\navg_bleu, avg_rouge = evaluate_translation(\n    model=transformer,\n    inputs=inputs_0[:20],\n    labels=labels.numpy()[:20],\n    input_sp_model=sp_eng,\n    target_sp_model=sp_urdu,\n    max_length=100\n)\n\nprint(f\"Average BLEU: {avg_bleu}\")\nprint(f\"Average ROUGE: {avg_rouge}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T17:02:16.681117Z","iopub.execute_input":"2024-11-16T17:02:16.682008Z","iopub.status.idle":"2024-11-16T17:02:59.037946Z","shell.execute_reply.started":"2024-11-16T17:02:16.681964Z","shell.execute_reply":"2024-11-16T17:02:59.036930Z"}},"outputs":[{"name":"stdout","text":"Input tensor: [[8907    3 1420   40 1042   39   35   56  317    8 2326   28   40    8\n  1136  778 8907    4    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7, 6, 6, 59, 59, 59, 59, 6, 59, 6, 59, 5, 32, 3, 7730, 3]\nInput tensor: [[8907    3 1420  222 3859  225  661  778 8907    4    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 29, 6, 6, 1044, 6, 35, 3, 7730, 3]\nInput tensor: [[8907    3 1420 1904   28    8  203   28 1034  778 8907    4    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 138, 29, 48, 6, 6, 6, 35, 3, 7730, 3]\nInput tensor: [[8907    3 1420   12   56   31  317  104   65  441   15   35   31  317\n    65  869   71  426  778 8907    4    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 42, 54, 54, 46, 15, 15, 15, 15, 15, 154, 54, 14, 5, 14, 5, 5, 3, 7730, 3]\nInput tensor: [[8907    3 1420  772  184    8  847  488  778 8907    4    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 48, 48, 29, 29, 6, 93, 32, 3, 7730, 3]\nInput tensor: [[8907    3 1420    8  488   28  126  228  310   31   98 1167   95 2007\n   778 8907    4    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 52, 32, 32, 81, 32, 32, 32, 81, 13, 121, 6, 13, 35, 3, 7730, 3]\nInput tensor: [[8907    3 1420   87   28  126   67   98  274 2392   99 1897   15  319\n    28  126   67   98 1703  975  778 8907    4    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 24, 24, 7730, 7730, 7730, 143, 25, 28, 15, 15, 15, 15, 76, 35, 35, 143, 143, 35, 35, 27, 27, 35, 32, 3, 7730, 3]\nInput tensor: [[8907    3 1420 2853 2612 2421  352   56   15    8  282  175    8 1184\n  1599  778 8907    4    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 260, 260, 259, 199, 59, 5, 1360, 5, 5, 1044, 901, 673, 3, 7730, 3]\nInput tensor: [[8907    3 1420  123   51    8 1288  339   42  151  179   51   72 3723\n    28  614   89   51    6 1355   71  126   67  849  400  417   15  332\n    56  778 8907    4    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 15, 7, 15, 7, 152, 7, 7, 20, 7, 7, 79, 7, 7, 7, 7, 20, 17, 66, 66, 107, 3, 7730, 3]\nInput tensor: [[8907    3 1420  126   67  357   42    8 1238   15 1170  696 6548   40\n  6570   15  913   42  215  379  320   28  192   65   98  491   74  778\n  8907    4    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 24, 24, 46, 46, 46, 46, 29, 24, 211, 29, 29, 29, 92, 104, 104, 104, 104, 104, 104, 104, 15, 15, 14, 15, 143, 143, 143, 72, 35, 105, 3, 7730, 3]\nInput tensor: [[8907    3 1420   15  126   67  357   42   40   73  151  140  274  545\n    35   31   15   73  151  316  545  270   31   15  227   98 1527  564\n    42    8  398  353  683  778 8907    4    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 7730, 60, 7730, 7730, 301, 35, 35, 35, 15, 15, 15, 15, 15, 15, 52, 25, 15, 52, 52, 52, 52, 7, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 72, 129, 15, 158, 3, 7730, 3]\nInput tensor: [[8907    3 1420   89   51   61   67  504  442  100   97  138   15   89\n    51   61   67  253 2478 1184 1099  778 8907    4    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 42, 42, 42, 7, 15, 143, 42, 15, 15, 15, 42, 42, 42, 42, 72, 72, 35, 6, 158, 3, 7730, 3]\nInput tensor: [[8907    3 1420  585  126   67   98 2479  903   89   51    8  506   71\n    74 1219   31  555   74  174   31  555   74   87   61   75   87  357\n   778 8907    4    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 28, 28, 24, 28, 24, 24, 24, 20, 24, 125, 7, 7, 7, 7, 125, 125, 7, 24, 24, 14, 14, 105, 72, 24, 93, 35, 3, 7730, 3]\nInput tensor: [[8907    3 1420   56  113    6 3332   28   97  493 3724  140  618    6\n  2726   85   97  510   15   97 1509   15  179   51    6 7882  618  341\n    97  867   15   71   74  179   51 1217  239  778 8907    4    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 7730, 7730, 7, 7, 7, 7, 15, 168, 24, 24, 6, 6, 24, 7, 6, 6, 24, 6, 6, 15, 24, 24, 24, 24, 6, 24, 24, 65, 24, 24, 24, 24, 24, 24, 24, 65, 24, 24, 24, 24, 33, 81, 3, 7730, 3]\nInput tensor: [[8907    3 1420   15 1950  145  179   96  227  264   67  154   65  357\n    42   56   15    8  203   28 1034 1060   61   96   87  251   40  354\n   778 8907    4    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 42, 42, 42, 72, 72, 20, 20, 42, 35, 42, 20, 13, 13, 35, 143, 143, 52, 52, 52, 143, 5, 143, 143, 13, 143, 52, 52, 52, 143, 129, 52, 14, 234, 32, 3, 7730, 3]\nInput tensor: [[8907    3 1420   61  715   35 2663   56   11   48    8  282   15    8\n   354  149   42  805   61 2663  352  541   15   61   96   87  834   28\n    89  778 8907    4    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 42, 42, 42, 35, 35, 35, 35, 35, 35, 35, 35, 15, 35, 35, 35, 35, 261, 35, 35, 260, 59, 118, 118, 259, 259, 259, 259, 199, 59, 59, 59, 35, 480, 3, 7730, 3]\nInput tensor: [[8907    3 1420   42   97  510   51    6 3040   92   56  140  165 8915\n  1324   97 3040   71   74  179   51 1721  626  561   61  428   35 1467\n  1705  778 8907    4    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 7, 35, 35, 35, 35, 35, 35, 35, 35, 7, 7, 7, 7, 6, 24, 7, 7, 7, 7, 7, 7, 7, 7, 7, 59, 7, 14, 14, 7, 6, 13, 24, 24, 3, 7730, 3]\nInput tensor: [[8907    3 1420  148   89   51  183   35   74  104   87 1135 3569   42\n     8  672   61  154   89   51   65   67 3746  778 8907    4    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7, 7, 7, 7, 7, 7730, 7730, 7, 46, 46, 42, 46, 66, 211, 7, 6, 20, 168, 168, 29, 24, 13, 211, 54, 211, 24, 24, 314, 122, 3, 7730, 3]\nInput tensor: [[8907    3 1420 1790 1619   89   51   61   67 1135 3569  149   61  104\n    87   98  182 2461   28   89  251   40  778 8907    4    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 78, 35, 35, 35, 35, 72, 35, 35, 76, 7, 105, 105, 35, 72, 6, 7, 6, 48, 24, 3, 7730, 3]\nInput tensor: [[8907    3 1420   15  148   89   51  183   35   74  357  113  333  145\n    98  816   61  154  253   65  227  357  113  126 5962   98  816 1790\n   360   61   96  541 5962  149   61  104   87  175   97 4535   15 1807\n  5979  778 8907    4    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 104, 104, 104, 104, 35, 35, 35, 35, 35, 15, 15, 15, 15, 35, 35, 42, 42, 42, 41, 42, 6, 35, 35, 22, 65, 42, 42, 42, 42, 65, 42, 42, 46, 350, 350, 143, 46, 405, 143, 143, 143, 143, 52, 405, 405, 405, 211, 211, 405, 13, 7, 28, 24, 122, 52, 66, 314, 3, 7730, 3]\nAverage BLEU: 0.05943213984467838\nAverage ROUGE: 0.4000000000000001\n","output_type":"stream"}],"execution_count":118},{"cell_type":"code","source":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Plotting the loss curves\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\nplt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T19:27:26.356760Z","iopub.execute_input":"2024-11-16T19:27:26.357139Z","iopub.status.idle":"2024-11-16T19:27:26.697844Z","shell.execute_reply.started":"2024-11-16T19:27:26.357102Z","shell.execute_reply":"2024-11-16T19:27:26.696881Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6UElEQVR4nO3dd3wUdeL/8fdms9nNpjdIAoHQQ1dROVCsKMVDUWyICpbzVNDzlPup56mg3nGent6dfi13p2DDdqfYQIoHFuwiSJcaWgKk92STnd8fk2yypExC2STk9Xw85pHszGdnP/vJEPadTxmbYRiGAAAAAACNCmrtCgAAAABAW0dwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAoA2aNq0aUpNTT2s586aNUs2m+3oVqiN2blzp2w2m+bNmxfw17bZbJo1a5bv8bx582Sz2bRz507L56ampmratGlHtT5Hcq0AAJqP4AQALWCz2Zq1rVixorWr2uHdfvvtstls2rp1a6Nl7rvvPtlsNv30008BrFnL7du3T7NmzdLq1atbuyo+NeH18ccfb+2qAEBABLd2BQCgPXnllVf8Hr/88staunRpvf39+/c/otf517/+Ja/Xe1jP/cMf/qB77rnniF7/eDBlyhQ99dRTmj9/vh544IEGy7z++usaPHiwhgwZctivc8011+jKK6+U0+k87HNY2bdvn2bPnq3U1FSdcMIJfseO5FoBADQfwQkAWuDqq6/2e/z1119r6dKl9fYfqqSkRG63u9mv43A4Dqt+khQcHKzgYH69Dx8+XL1799brr7/eYHD66quvtGPHDv35z38+otex2+2y2+1HdI4jcSTXCgCg+RiqBwBH2VlnnaVBgwbphx9+0BlnnCG3263f//73kqT33ntPF1xwgZKTk+V0OtWrVy89/PDDqqqq8jvHofNW6g6L+uc//6levXrJ6XTqlFNO0Xfffef33IbmONlsNs2YMUMLFizQoEGD5HQ6NXDgQH388cf16r9ixQqdfPLJcrlc6tWrl55//vlmz5v6/PPPddlll6lbt25yOp1KSUnRb3/7W5WWltZ7f+Hh4dq7d68mTpyo8PBwJSQkaObMmfXaIi8vT9OmTVNUVJSio6M1depU5eXlWdZFMnudNm3apFWrVtU7Nn/+fNlsNk2ePFkVFRV64IEHNGzYMEVFRSksLEyjRo3S8uXLLV+joTlOhmHokUceUdeuXeV2u3X22Wdr/fr19Z6bk5OjmTNnavDgwQoPD1dkZKTGjRunNWvW+MqsWLFCp5xyiiTpuuuu8w0HrZnf1dAcp+LiYt11111KSUmR0+lUv3799Pjjj8swDL9yLbkuDteBAwd0ww03qHPnznK5XBo6dKheeumleuXeeOMNDRs2TBEREYqMjNTgwYP197//3Xfc4/Fo9uzZ6tOnj1wul+Li4nT66adr6dKlR62uANAU/iQJAMdAdna2xo0bpyuvvFJXX321OnfuLMn8kB0eHq4777xT4eHh+t///qcHHnhABQUFeuyxxyzPO3/+fBUWFurXv/61bDab/vKXv+iSSy7R9u3bLXsevvjiC73zzju69dZbFRERoX/84x+aNGmSdu3apbi4OEnSjz/+qLFjxyopKUmzZ89WVVWVHnroISUkJDTrfb/99tsqKSnRLbfcori4OH377bd66qmntGfPHr399tt+ZauqqjRmzBgNHz5cjz/+uJYtW6a//vWv6tWrl2655RZJZgC56KKL9MUXX+jmm29W//799e6772rq1KnNqs+UKVM0e/ZszZ8/XyeddJLfa7/11lsaNWqUunXrpqysLP373//W5MmT9atf/UqFhYV64YUXNGbMGH377bf1hsdZeeCBB/TII49o/PjxGj9+vFatWqXzzz9fFRUVfuW2b9+uBQsW6LLLLlOPHj20f/9+Pf/88zrzzDO1YcMGJScnq3///nrooYf0wAMP6KabbtKoUaMkSSNHjmzwtQ3D0IUXXqjly5frhhtu0AknnKDFixfrd7/7nfbu3asnn3zSr3xzrovDVVpaqrPOOktbt27VjBkz1KNHD7399tuaNm2a8vLy9Jvf/EaStHTpUk2ePFnnnnuuHn30UUnSxo0btXLlSl+ZWbNmac6cObrxxht16qmnqqCgQN9//71WrVql884774jqCQDNYgAADtv06dONQ3+VnnnmmYYk47nnnqtXvqSkpN6+X//614bb7TbKysp8+6ZOnWp0797d93jHjh2GJCMuLs7Iycnx7X/vvfcMScYHH3zg2/fggw/Wq5MkIyQkxNi6datv35o1awxJxlNPPeXbN2HCBMPtdht79+717duyZYsRHBxc75wNaej9zZkzx7DZbEZ6errf+5NkPPTQQ35lTzzxRGPYsGG+xwsWLDAkGX/5y198+yorK41Ro0YZkoy5c+da1umUU04xunbtalRVVfn2ffzxx4Yk4/nnn/eds7y83O95ubm5RufOnY3rr7/eb78k48EHH/Q9njt3riHJ2LFjh2EYhnHgwAEjJCTEuOCCCwyv1+sr9/vf/96QZEydOtW3r6yszK9ehmH+rJ1Op1/bfPfdd42+30OvlZo2e+SRR/zKXXrppYbNZvO7Bpp7XTSk5pp87LHHGi3zt7/9zZBkvPrqq759FRUVxogRI4zw8HCjoKDAMAzD+M1vfmNERkYalZWVjZ5r6NChxgUXXNBknQDgWGKoHgAcA06nU9ddd129/aGhob7vCwsLlZWVpVGjRqmkpESbNm2yPO8VV1yhmJgY3+Oa3oft27dbPnf06NHq1auX7/GQIUMUGRnpe25VVZWWLVumiRMnKjk52Veud+/eGjdunOX5Jf/3V1xcrKysLI0cOVKGYejHH3+sV/7mm2/2ezxq1Ci/97Jw4UIFBwf7eqAkc07Rbbfd1qz6SOa8tD179uizzz7z7Zs/f75CQkJ02WWX+c4ZEhIiSfJ6vcrJyVFlZaVOPvnkBof5NWXZsmWqqKjQbbfd5je88Y477qhX1ul0KijI/K+4qqpK2dnZCg8PV79+/Vr8ujUWLlwou92u22+/3W//XXfdJcMwtGjRIr/9VtfFkVi4cKESExM1efJk3z6Hw6Hbb79dRUVF+vTTTyVJ0dHRKi4ubnLYXXR0tNavX68tW7Yccb0A4HAQnADgGOjSpYvvg3hd69ev18UXX6yoqChFRkYqISHBt7BEfn6+5Xm7devm97gmROXm5rb4uTXPr3nugQMHVFpaqt69e9cr19C+huzatUvTpk1TbGysb97SmWeeKan++3O5XPWGANatjySlp6crKSlJ4eHhfuX69evXrPpI0pVXXim73a758+dLksrKyvTuu+9q3LhxfiH0pZde0pAhQ3zzZxISEvTRRx816+dSV3p6uiSpT58+fvsTEhL8Xk8yQ9qTTz6pPn36yOl0Kj4+XgkJCfrpp59a/Lp1Xz85OVkRERF++2tWeqypXw2r6+JIpKenq0+fPr5w2Fhdbr31VvXt21fjxo1T165ddf3119ebZ/XQQw8pLy9Pffv21eDBg/W73/2uzS8jD+D4QnACgGOgbs9Ljby8PJ155plas2aNHnroIX3wwQdaunSpb05Hc5aUbmz1NuOQSf9H+7nNUVVVpfPOO08fffSR7r77bi1YsEBLly71LWJw6PsL1Ep0nTp10nnnnaf//ve/8ng8+uCDD1RYWKgpU6b4yrz66quaNm2aevXqpRdeeEEff/yxli5dqnPOOeeYLvX9pz/9SXfeeafOOOMMvfrqq1q8eLGWLl2qgQMHBmyJ8WN9XTRHp06dtHr1ar3//vu++Vnjxo3zm8t2xhlnaNu2bXrxxRc1aNAg/fvf/9ZJJ52kf//73wGrJ4COjcUhACBAVqxYoezsbL3zzjs644wzfPt37NjRirWq1alTJ7lcrgZvGNvUTWRrrF27Vj///LNeeuklXXvttb79R7LqWffu3fXJJ5+oqKjIr9dp8+bNLTrPlClT9PHHH2vRokWaP3++IiMjNWHCBN/x//znP+rZs6feeecdv+F1Dz744GHVWZK2bNminj17+vYfPHiwXi/Of/7zH5199tl64YUX/Pbn5eUpPj7e97g5KxrWff1ly5apsLDQr9epZihoTf0CoXv37vrpp5/k9Xr9ep0aqktISIgmTJigCRMmyOv16tZbb9Xzzz+v+++/39fjGRsbq+uuu07XXXedioqKdMYZZ2jWrFm68cYbA/aeAHRc9DgBQIDU/GW/7l/yKyoq9Mwzz7RWlfzY7XaNHj1aCxYs0L59+3z7t27dWm9eTGPPl/zfn2EYfktKt9T48eNVWVmpZ5991revqqpKTz31VIvOM3HiRLndbj3zzDNatGiRLrnkErlcribr/s033+irr75qcZ1Hjx4th8Ohp556yu98f/vb3+qVtdvt9Xp23n77be3du9dvX1hYmCQ1axn28ePHq6qqSk8//bTf/ieffFI2m63Z89WOhvHjxyszM1Nvvvmmb19lZaWeeuophYeH+4ZxZmdn+z0vKCjId1Pi8vLyBsuEh4erd+/evuMAcKzR4wQAATJy5EjFxMRo6tSpuv3222Wz2fTKK68EdEiUlVmzZmnJkiU67bTTdMstt/g+gA8aNEirV69u8rlpaWnq1auXZs6cqb179yoyMlL//e9/j2iuzIQJE3Taaafpnnvu0c6dOzVgwAC98847LZ7/Ex4erokTJ/rmOdUdpidJv/zlL/XOO+/o4osv1gUXXKAdO3boueee04ABA1RUVNSi16q5H9WcOXP0y1/+UuPHj9ePP/6oRYsW+fUi1bzuQw89pOuuu04jR47U2rVr9dprr/n1VElSr169FB0dreeee04REREKCwvT8OHD1aNHj3qvP2HCBJ199tm67777tHPnTg0dOlRLlizRe++9pzvuuMNvIYij4ZNPPlFZWVm9/RMnTtRNN92k559/XtOmTdMPP/yg1NRU/ec//9HKlSv1t7/9zdcjduONNyonJ0fnnHOOunbtqvT0dD311FM64YQTfPOhBgwYoLPOOkvDhg1TbGysvv/+e/3nP//RjBkzjur7AYDGEJwAIEDi4uL04Ycf6q677tIf/vAHxcTE6Oqrr9a5556rMWPGtHb1JEnDhg3TokWLNHPmTN1///1KSUnRQw89pI0bN1qu+udwOPTBBx/o9ttv15w5c+RyuXTxxRdrxowZGjp06GHVJygoSO+//77uuOMOvfrqq7LZbLrwwgv117/+VSeeeGKLzjVlyhTNnz9fSUlJOuecc/yOTZs2TZmZmXr++ee1ePFiDRgwQK+++qrefvttrVixosX1fuSRR+RyufTcc89p+fLlGj58uJYsWaILLrjAr9zvf/97FRcXa/78+XrzzTd10kkn6aOPPtI999zjV87hcOill17Svffeq5tvvlmVlZWaO3dug8Gpps0eeOABvfnmm5o7d65SU1P12GOP6a677mrxe7Hy8ccfN3jD3NTUVA0aNEgrVqzQPffco5deekkFBQXq16+f5s6dq2nTpvnKXn311frnP/+pZ555Rnl5eUpMTNQVV1yhWbNm+Yb43X777Xr//fe1ZMkSlZeXq3v37nrkkUf0u9/97qi/JwBoiM1oS3/qBAC0SRMnTmQpaABAh8YcJwCAn9LSUr/HW7Zs0cKFC3XWWWe1ToUAAGgD6HECAPhJSkrStGnT1LNnT6Wnp+vZZ59VeXm5fvzxx3r3JgIAoKNgjhMAwM/YsWP1+uuvKzMzU06nUyNGjNCf/vQnQhMAoEOjxwkAAAAALDDHCQAAAAAsEJwAAAAAwEKHm+Pk9Xq1b98+RUREyGaztXZ1AAAAALQSwzBUWFio5ORk333jGtPhgtO+ffuUkpLS2tUAAAAA0Ebs3r1bXbt2bbJMhwtOERERkszGiYyMbOXaHN88Ho+WLFmi888/Xw6Ho7Wr0yHQ5oFHmwcW7R14tHng0eaBRXsHXltq84KCAqWkpPgyQlM6XHCqGZ4XGRlJcDrGPB6P3G63IiMjW/0fRUdBmwcebR5YtHfg0eaBR5sHFu0deG2xzZszhYfFIQAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnND2leRI21dIBRmtXRMAAAB0UMGtXQGgnpIcKf1LaecX5rZ/nSRDkk3qPlIaeLE0YKIUntDKFUW7lLVV+vEVyfBKQ66QEge1do0AAEA7QHBC62s0KNUR2VUq2COlrzS3Rf9P6nGGNPASqf8EyR3bKlVHO+H1SluXSd8+b36t8eU/pOQTpROvkQZfKrmiWq+OAACgTSM4IfCaE5Ti+0mpp5tb99OkiM5S3m5pwwJp3TvSvlXm8L3tK6SP7pR6nWOGqLTxfPhFrdI8afVr0rf/knJ3VO+0SX3HSPYQafMiad+P5rb4PmnARdJJ15jXnM3WmjUHAABtDMEJx15prrTtu+qg9LmU2VBQ6lsnKJ1uBqVDRadII28zt5zt0vp3pXXvSvvXSluWmJvdKfU5zxzO12+cFBIWkLeINmb/Bunbf0o/vSl5Ssx9riizZ+mUG6TYnua+4ixpzRvm0L2Dm6Sf3jC3mB7SiVdLJ1wlRSa33vsAAABtBsEJR19JjrTrKwVt/1Rnblqk4B9367CCUlNie0qj7jK3gz9L69+R1v1XyvpZ2vShuTncZs/CwEvMMOUIPWpvEW1QVaW0eaEZmHZ+Xru/0wDp1JukIZfXD9Jh8dLIGdKI6dKe76UfXzZ7NHN3SP97WFr+R6n3eWYvVN+xkt0R2PcEAADaDIITjlxpbp2hd7U9SnZJ0TVljjQoNSWhr3TWPdKZd0v711eHqOoPv+vfNbeQCHMY38BLzGF9wSFH7/XRuoqzpVUvSd+/KOXvNvfZgqS0C6RTf21ec1bD7mw2KeUUcxszR9rwntkLtesracticwtLkIZeKZ14rXnNAQCADoXghJZrJCj5ie+rqm4jtSrHrRMumi5HTNdjXy+bzVwhLXGQdM795ryV9e9I6xeYH6h/etPcXNFS/19KgyZJqWdIdv4ZtEv7Vptzl9a+LVWVm/vccdJJU6WTrzeHdh4OZ7h04hRzy9piBqjVr0vFB6QvnzK3lOHmUL6Bl0hBzqP2lgAAQNvFJ0ZYK82V0r+qE5TWqjlD77wej/YtXKgTwo9i71Jz2WxSl5PMbfRD0t7vzaF86xdIRZnSj6+amzteGnCh+QG4+0gpyB74uqL5Kiukje+bw/F2f1O7P+kEafivzZ+jw3X0Xi++j3TeQ2YQ37JEWvWK+XX3N+a26B7ZB0xUTElPyTCszwcAANotghNqGYbkrZTKCswPhU0Fpbg+tUEp9XQpIrFVqtwsQUFSyqnmNuZPZm/Z+nfM4VglWeYQr+9flMITpYETzZ6orqewqlpbUrhf+mGu9P1cM/hKUlCweT+v4b8+9j8vu8Mc+pd2gVSYKa153QxROdsUtOY1nSHJeP4N6aRrzeF84Z2OXV0AAECrIDi1pvy9UmGGVOWRqipqv3o9dfbV7K9TxutpeH+Dz630P4/3kPJ1z+H1NF7X9hSUmhJkl3qMMrdxj0k7PjVD1MYPzA/k3zxnblEpZogaeIl5nx9CVOAZhrTnO+mb582QW3N9hnc2h+INm9Y612FEonT6b6XT7pB2fSXvDy/Ju+4dBWdvkZbeL30y21xI4sRrpN6jGQoKAMBxgv/RW9PXz0hfPd3atWjY8RKUmmIPlnqfa24XPClt+58ZojYtNOdE1cxniekhDbrEDFGdBxKijjVPmflz+OZ5KWN17f6U4ebqeP0vbBuLe9hsUveRqko+RUt0tsZ0LVbwmvnmsNCalR0jkqShk835UHG9WrvGQOvK22XOiU0ZLoXFtXZtAKDFCE6tyR0nRXUzhwHZQ8wP8vaQ6s0hBTlqv/d9ddSWCTqkvP2Q8kGHlG/2+Z1SiLu1WyewgkOkfmPNzVMqbVlqfnjf/LG5Ot/nfzW3+H61Iaq5K6t5vVJlWe3mKa3zfZlUWVr9tbHjzX9OcGWZzvWGyJ4/11yyPSZViu1hfo1JlZwRx7ARj1D+Hum7F8wV8kqyzX12pzT4UjMwJZ/QqtVrSqU9VMaJk6RTbzDvIfXjq+b9oAozpC+eMLfup5vLmve/sOP9+0LHZBjmSqebPjL/kJD5k7nfHiL1n2Au5JI6yhxODQDtAMGpNY2609zQtjhCzQUjBlwolRdJP39sLmm+ZamUtVlaMcfcOg+WorpaB5+aFd8CwCYpXJK275e2L69fwB1fJ0j18P8+vHPgP8AYhjmX7tt/mh+ujCpzf2RX80a1J11r3mupPek8QBr7J2n0LPO+Uj++Im39REr/wtwW/s6cR3fSNVLySfRg4vhSVSnt/ro2LOXtqj1mCzKHQeelm4v1rPuv+bvnpGukE64+urepAIBjgOAENMUZbvZ4DL5UKss3h/Gtf8cc1rd/rbm1RFCwFBxqrvzm++r03xfsNMNbsKv6a/OPewy7vvnfR/pFWqKC83dJuTvNHrOcHVJpjrkYRkmWOXfoUMGu2p6pmB7+vVXR3Y/uanUVxdJPb5nLiR9YX7s/dZTZu9RvfPufGxQcUj1PbqLZm7Z6vhmi8naZC138MFfqNND80DjkCskd29o1Bg5PRYn5h5pNH0mbF5m/a2oEu8x756VdYM79C4uXMtZIP7xk3kogd4f0yUPS//4o9Rtn9kL1PpcVTgG0Se38kwkQQK4o6YTJ5laSY/YieEqaH3KCXcc+DHg8yo7YJmPoeMnh8D9Wll8dpHaaQaomVOXulPJ2mz1kBzeZWz02KTK54VAV08P80N+cnpOcHdJ3/zYDRFm+uc/hNoPDqb8y55Adj6K6Smf+P2nUTHOlyh9fkTa8b4bGj++Rlj5gfrAceImUONgMqgxfQltWkmP2xm/6yPxdWFlaeyw0Ruo7zryme50thYT5PzdpqPTLJ6TzHzZvEbHqJXMl15q5gZFdzT8onHi1+W8HANoIghNwONyx0pDLWrsWLeOKMj+wJA2tf6zKY/aK1PRO1Q1VOTulikKpYK+5pa+s//yQCCk2teFgFdnVDAvf/lP6ebF8S9vHpEqn/Mq80WxozDF5y21OUJDU80xzG58rrf2PtOplc+7H+nfNTZJCwqWENHPYX6eBtV+ZUI/WlLdL2rbEDEvpKyXDW3ssqlvtkv3dRjTvj0QhYbU3mz6w0fy3sOZ1qWCPORz600fNlSlPmir1HWPOwQWAVkRwAmB+IImtnvN06OJvhmH+ddkXpA4JVgV7zWCVubb6nl8Wep1r3nup93kdu1clNMbsZTv1V+bQpR9fM+8xlrVZqigyV+fb+73/c8I6HRKmBpgBi8UmcCwYhpS5VkEb3tdZm96U48dd/scTB0v9qsNS4uAjm6/Xqb80do507oNmr9MP88w/uGxZYm7hnaUTppg9UbE9j+htAcDhIjgBaJrNZvZ0hMVJXU+uf9xTZk72bihU5e40hwCGRJh/VT7lRim+T2Dr3x7U7Qms8kjZ28xhfPs3SAeqt9ydUvEBafsBafuKOk+2mR8kO/U3hzp2GmB+je3JPBG0XFWltOur6sUdPpLyd8kuKUqSYQuSrftpZlDqN16K6X70X9/hqp1Xmr3N7IVa/ZpUtL92hcoeZ0rDpkppvzSHQwNAgBCcABwZh0tK6Gduh/J6zQ/7rihzrhes2R1SpzRzGzSpdn95kTn/bP96M0jVfC3JlnK2mdumD2vLB1f/XDoNrA5V1T1VEYltdyU/wzDnDZbkmO+rJFsqza39viRH9uKDOnXvLtk/XCyFJ5iLDbjjzBUj3dUB3x1nDndsq++zrakoMRe82fSR9PMis81rBIfK2/NsrS7rosGTZsoRFcB7+sX1ks6bLZ3zB3PRiVUvmfOpdnxqbqGx0glXmUP5mnt7CAA4AgQnAMdOUNDxefPk1uAMN3v86vb6GYZUdKC2V2r/BrOn6sAmc7J+xhpzqys0xn+oX6cBZrByRR7d+hqGuXpiaZ0QVFInBPn259QGpdIcs4eyCUGSkiRpzaqmX9/u9A9S7vg6Iat6qxu6QmPa/0qOLVGcVbu4w7b/+bd7aKy5wl3aBVLPs1Vlc2j3woUa7G6lOXZ2R+0tIvJ2mfdJ+/FVc5jwV0+bW7cRZoAacBFDVwEcMx3ofwkAOM7YbOa9byI6m6uX1fBWmUP7anqlakJVzjazN6HmnlJ1RXWrDVM1Q/7iepvLqhuGOe+qpE7Y8Qs+dcNQnf2Hew+zIEedgBNbvcVJobGqckVr3cYtGtQrWfayvOol9rPNIFBSveR+ZfX90wr3mVvzGlMKjW6496qx0OVwt69erZwd5r3FNn1kDseru7hDdDcpbYKUNl5K+YV/iPR4Al/XxkR3k87+vXTm3dLWZeay5j9/bL6fXV9Ji+6WhlxuDuVLHNzatQVwnCE4AcDxJshuDnOK62X+lb6Gp1Q6uNl/qN+BjVJhhpS/y9x+/rjOeRxmaCnNlaoqDq8u9pDasBEac0ggMsNQvYDUxDA7r8ejnVkLNeD08bIfuuS+VDvcrzirTk9Xdp3H1QGr7uPSXEmG+bU0V8re2rz3FuyqDlmx5nsLdpm9I/YQc+6N3WH2fNlDzABqr7P5jodUl3E08RxnI+d1NB3cDMNcsbFmvtL+df7HE4eY84TSLjDDcnsKgUF2c6W9vmOkggxzHtSql835lt/9y9ySTzID1KBJkjOitWsM4DhAcAKAjsIRKiWfYG51leT4D/XbXx2oKgrNSfk1aoa/ueMkd50Q1FD4qdkXEhbYD+Q2m/maIWHNX7ygqrLOXKoGerD8glf191XlZs9WwR5zay32QwNZne9L8/x73Gx2qfvI6rA03uy9OR5EJklnzJROv9Oc+7TqJWnjh9K+Veb28e+lwZOkk6ZJXU5qXwGxLTEM2g4dHsEJADo6d6yUerq51TAMcz5JaW5tGGpvQ9Oayx5sLjQRntC88jXzt+r2YJXmmWGqqkKqrDC/VpWbqyRWVn+tt6+idmv0OTXlqvcZVf51qXl+Yxxuqfe55rLhfceYP8vjVVCQOWS119lmuF093+yFyt5ifl31stR5kDkXasjl5tBMNK3ogLkwx+aF0vZPzeun6ym1W9JQc4EgoIMgOAEA6rPZzB6bY7HkdHtns5mLdTjDA98+3qrmhy2b3VxMpCOuaBkWL512uzTyNvP+aKtekja8Zw5XXPQ7aen90oCJ5lC+biOOzz8IHK6DP0ubP5I2LZT2fCffTcslc0GODXulDQvMx0EOKWmIf5iK7kZ74rhFcAIAoL0IsktBoR0zDB0Om01KPc3cxj0q/fS2GaL2r5N+esPc4vtKfceaPa7dfmHePqEj8VZJe76vDUvZW/yPJ59kDu3sM0YqyzfD1J7vpT3fSsUHpb0/mNs3z5nlwzpVh6iTpZRTpeQTzaGzCBzDMIdZH9hozms9uMkcWuyKklzR1V+jzF7Xmu9r9jsjCL5NIDgBAIDjX2iMNPwm6dRfSXtXSavmSWv/K2X9bG5f/kOyBZmLZqSeLnU/Teo+wnze8cZTag692/ShuSBM8cHaY0EOqccZZljqN16KTPZ/bo9R5lfDMBfj2PO9GaZ2f2suRlJ8wAxhmz8yy9ns5oqdXU+Rup5qfo3rxYfzo6EmIB3cZN6G4uDG6q+bpLK8wzunLUhyRjYcqnxhK7rxEBbsOq5/tgQnAADQcdhsUtdh5jbmT+Ycnp2fSzu/kHK2Sxmrze2rpyXZpMRBUuqo6iA1sv3OEyvJ8b93l6ek9pgzSup7vhmUeo9u3n3dbDYpJtXcBl9q7vOUShk/VfdKfWuGqoK9UuZac/v+RbNcaIzUpbpHquvJUpdhHa+nryVq7tlXNxgd3GT2KDUWkGxBUkwP8z59CWlmT1JZfp0tr/b70jzzcVWFeZuCsrzDD172kGb1bNkc4Uoo+FnynC01tEJqG0VwAgAAHZMzwlwoYsjl5uOCfeacqJ2fSztXmsPWaj70f/2MWabzIDNEpZ5mfg2Lb736W2nq3l2RXWt7lbqfZq7IeKQcoVK34eZWI3+vtPd7s0dqz/dmKC3NlbYuNTdJkk1K6Oc/Vyqhnzk0tSPxBaQ6wajm+9Lchp/jF5D6SQn9pU5pUlyfli/c4SlrIFDl1wapusGrNK9+CDO8ZvgqPujfi9mAYEkjJXlKr5bcR/kG7McQwQkAAEAyh6UNvrS2B6Vwv3mz6J0rpfSV5gfY/evM7dvnzTIJ/atXpTxN6n5681dnPBa8XinjR3Ou0uaF5m0G6uo82AxLaReYQxIDMaQqqou5DbjIfFxZYbbfnu9qt9ydtQHhx1fMciER1T2D1UGqy8nmTamPB4ZhBou6wahmqF1jAUk2KbZHbTBKqA5K8X2O3pxHh0tyJEoRiS1/bs2N0hsKVPWCVr68pTkqPLBH7nbW09iqwWnWrFmaPXu2375+/fpp06ZNDZafN2+errvuOr99TqdTZWVlx6yOAACgg4robN5Ad9Ak83HRQTNA7fzC/Hpgg/lh9+BG86a7khTfr3pBitPNIBXR+djWsbJC2vlZbVgqzKg9ZrObdel3gdRvXNtYJTM4xLyfVpeTpOG/NvcVHaidK7XnO3MOWkWhtH2FudWI7VW78ETXU8zeP3sb7gPwC0ib/YfaleY08qQ6ASmhX+1Qu6MZkI4Fm83swXVGSEqxLF7l8WjFwoUa384WDmn1q23gwIFatmyZ73FwcNNVioyM1ObNm32PbcfxBDQAANCGhCdIAyeamyQVZ5sBqiZM7V8nZW02t5r5PHG9a0NU6mn1F1s4HKV50pal5gIMW5aZIaNGSHjtvbv6nNc+5mSFd6ruCRtvPq6qNENGzQp+u781h03mbDO3n94wywWHSmEJ5j28bEFmUAyyV3+tfmwLqrPvkMfV39tl0yn7D8r+zn/NIOZ3rgaeX/f89Y7ZpIKM2qF2lgEpzdzaS0Dq4Fo9OAUHBysxsfldgjabrUXlAQAAjomwOGnAheYmmQsw7PrKDFE7vzDnRmVvNbcf5pllYntWz5EaZQapqK7Ne6283dU3o/3IPLe3svZYeGdzrlLaBeZ52/tNae3BUuJgczv5enNfSY7ZE+VbeOIHqTxfyt91xC8XJClZkvK/P+Jz1Ve9iEZNMEpIM4faxfclILVDrR6ctmzZouTkZLlcLo0YMUJz5sxRt27dGi1fVFSk7t27y+v16qSTTtKf/vQnDRw4sNHy5eXlKi8v9z0uKCiQJHk8Hnk8nqP3RlBPTfvSzoFDmwcebR5YtHfg0eYt4IiQep1vbpJUmifb7q9l2/WlbOkrZdu/Vrac7ebqfdVzeYzo7jK6nSZv95Eyuo2UoruZbW0Yqty7WkHblijo50Wy7V/r91JGfD95+46T0XecjOQTzd6OGsfjz8oRIaWeaW6SuRBBzjbZygolo6p685r3pfJ9rap9bHjrPK4y54NV76vyVGjThvXqn9ZXdpvqlD3kOYa3dt+h564uY/NWyQiLlxHfT0ZCmtnj6HA3/J6Ox59TM7Wl3ystqYPNMAzDutixsWjRIhUVFalfv37KyMjQ7NmztXfvXq1bt04RERH1yn/11VfasmWLhgwZovz8fD3++OP67LPPtH79enXt2vBfbBqaRyVJ8+fPl9vdyIUMAABwlAVXlSi2aIviizYqvmiTokp2KkhevzIlIfHKdfdQTMkOuSuyfPsN2ZQT1kcZUcOUGX2Sip3HeO4U0EGUlJToqquuUn5+viIjm17hr1WD06Hy8vLUvXt3PfHEE7rhhhssy3s8HvXv31+TJ0/Www8/3GCZhnqcUlJSlJWVZdk4ODIej0dLly7VeeedJ0c7WqO/PaPNA482DyzaO/Bo82OovFC2Pd9W90h9KVvGj7LVGYJnBLtk9Dzb7FnqfX7bXvq8HeMaD7y21OYFBQWKj49vVnBq9aF6dUVHR6tv377aunVrs8o7HA6deOKJTZZ3Op1yOp0NPre1f1AdBW0deLR54NHmgUV7Bx5tfgw4YqW0seYmSRXF0u5vVLVnlb7fWaCTLrtLDneUgpo+C44SrvHAawtt3pLXb1P/FouKirRt2zYlJSU1q3xVVZXWrl3b7PIAAABtVkiY1OsceUf+RpnRwxqfGwOgVbRqcJo5c6Y+/fRT7dy5U19++aUuvvhi2e12TZ48WZJ07bXX6t577/WVf+ihh7RkyRJt375dq1at0tVXX6309HTdeOONrfUWAAAAAHQArTpUb8+ePZo8ebKys7OVkJCg008/XV9//bUSEsy7bu/atUtBQbXZLjc3V7/61a+UmZmpmJgYDRs2TF9++aUGDBjQWm8BAAAAQAfQqsHpjTfeaPL4ihUr/B4/+eSTevLJJ49hjQAAAACgvjY1xwkAAAAA2iKCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYaNXgNGvWLNlsNr8tLS2tWc994403ZLPZNHHixGNbSQAAAAAdXnBrV2DgwIFatmyZ73FwsHWVdu7cqZkzZ2rUqFHHsmoAAAAAIKkNBKfg4GAlJiY2u3xVVZWmTJmi2bNn6/PPP1deXt6xqxwAAAAAqA0Epy1btig5OVkul0sjRozQnDlz1K1bt0bLP/TQQ+rUqZNuuOEGff7555bnLy8vV3l5ue9xQUGBJMnj8cjj8Rz5G0CjatqXdg4c2jzwaPPAor0DjzYPPNo8sGjvwGtLbd6SOtgMwzCOYV2atGjRIhUVFalfv37KyMjQ7NmztXfvXq1bt04RERH1yn/xxRe68sortXr1asXHx2vatGnKy8vTggULGn2NWbNmafbs2fX2z58/X263+2i+HQAAAADtSElJia666irl5+crMjKyybKtGpwOlZeXp+7du+uJJ57QDTfc4HessLBQQ4YM0TPPPKNx48ZJUrOCU0M9TikpKcrKyrJsHBwZj8ejpUuX6rzzzpPD4Wjt6nQItHng0eaBRXsHHm0eeLR5YNHegdeW2rygoEDx8fHNCk6tPlSvrujoaPXt21dbt26td2zbtm3auXOnJkyY4Nvn9XolmfOkNm/erF69etV7ntPplNPprLff4XC0+g+qo6CtA482DzzaPLBo78CjzQOPNg8s2jvw2kKbt+T121RwKioq0rZt23TNNdfUO5aWlqa1a9f67fvDH/6gwsJC/f3vf1dKSkqgqgkAAACgg2nV4DRz5kxNmDBB3bt31759+/Tggw/Kbrdr8uTJkqRrr71WXbp00Zw5c+RyuTRo0CC/50dHR0tSvf0AAAAAcDS1anDas2ePJk+erOzsbCUkJOj000/X119/rYSEBEnSrl27FBTUqvfoBQAAAIDWDU5vvPFGk8dXrFjR5PF58+YdvcoAAAAAQCPozgEAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAAC4cVnHbv3q09e/b4Hn/77be644479M9//vOoVQwAAAAA2orDCk5XXXWVli9fLknKzMzUeeedp2+//Vb33XefHnrooaNaQQAAAABobYcVnNatW6dTTz1VkvTWW29p0KBB+vLLL/Xaa69p3rx5R7N+AAAAANDqDis4eTweOZ1OSdKyZct04YUXSpLS0tKUkZFx9GoHAAAAAG3AYQWngQMH6rnnntPnn3+upUuXauzYsZKkffv2KS4u7qhWEAAAAABa22EFp0cffVTPP/+8zjrrLE2ePFlDhw6VJL3//vu+IXwAAAAAcLwIPpwnnXXWWcrKylJBQYFiYmJ8+2+66Sa53e6jVjkAAAAAaAsOq8eptLRU5eXlvtCUnp6uv/3tb9q8ebM6dep0VCsIAAAAAK3tsILTRRddpJdfflmSlJeXp+HDh+uvf/2rJk6cqGefffaoVhAAAAAAWtthBadVq1Zp1KhRkqT//Oc/6ty5s9LT0/Xyyy/rH//4x1GtIAAAAAC0tsMKTiUlJYqIiJAkLVmyRJdccomCgoL0i1/8Qunp6Ue1ggAAAADQ2g4rOPXu3VsLFizQ7t27tXjxYp1//vmSpAMHDigyMvKoVhAAAAAAWtthBacHHnhAM2fOVGpqqk499VSNGDFCktn7dOKJJzb7PLNmzZLNZvPb0tLSGi3/zjvv6OSTT1Z0dLTCwsJ0wgkn6JVXXjmctwAAAAAAzXZYy5FfeumlOv3005WRkeG7h5MknXvuubr44otbdK6BAwdq2bJltRUKbrxKsbGxuu+++5SWlqaQkBB9+OGHuu6669SpUyeNGTOm5W8EAAAAAJrhsIKTJCUmJioxMVF79uyRJHXt2vWwbn4bHBysxMTEZpU966yz/B7/5je/0UsvvaQvvviC4AQAAADgmDms4OT1evXII4/or3/9q4qKiiRJERERuuuuu3TfffcpKKj5IwC3bNmi5ORkuVwujRgxQnPmzFG3bt0sn2cYhv73v/9p8+bNevTRRxstV15ervLyct/jgoICSZLH45HH42l2PdFyNe1LOwcObR54tHlg0d6BR5sHHm0eWLR34LWlNm9JHWyGYRgtfYF7771XL7zwgmbPnq3TTjtNkvTFF19o1qxZ+tWvfqU//vGPzTrPokWLVFRUpH79+ikjI0OzZ8/W3r17tW7dOt+qfYfKz89Xly5dVF5eLrvdrmeeeUbXX399o68xa9YszZ49u97++fPny+12N6ueAAAAAI4/JSUluuqqq5Sfn2+5yN1hBafk5GQ999xzuvDCC/32v/fee7r11lu1d+/elp5Sknkz3e7du+uJJ57QDTfc0GAZr9er7du3q6ioSJ988okefvhhLViwoN4wvhoN9TilpKQoKyuLFQCPMY/Ho6VLl+q8886Tw+Fo7ep0CLR54NHmgUV7Bx5tHni0eWDR3oHXltq8oKBA8fHxzQpOhzVULycnp8HV79LS0pSTk3M4p5QkRUdHq2/fvtq6dWujZYKCgtS7d29J0gknnKCNGzdqzpw5jQYnp9Mpp9NZb7/D4Wj1H1RHQVsHHm0eeLR5YNHegUebBx5tHli0d+C1hTZvyesf1nLkQ4cO1dNPP11v/9NPP60hQ4YcziklSUVFRdq2bZuSkpKa/Ryv1+vXowQAAAAAR9th9Tj95S9/0QUXXKBly5b57uH01Vdfaffu3Vq4cGGzzzNz5kxNmDBB3bt31759+/Tggw/Kbrdr8uTJkqRrr71WXbp00Zw5cyRJc+bM0cknn6xevXqpvLxcCxcu1CuvvKJnn332cN4GAAAAADTLYQWnM888Uz///LP+7//+T5s2bZIkXXLJJbrpppv0yCOPaNSoUc06z549ezR58mRlZ2crISFBp59+ur7++mslJCRIknbt2uW3Ql9xcbFuvfVW7dmzR6GhoUpLS9Orr76qK6644nDeBgAAAAA0y2Hfxyk5Obne6nlr1qzRCy+8oH/+85/NOscbb7zR5PEVK1b4PX7kkUf0yCOPtKieAAAAAHCkDmuOEwAAAAB0JAQnAAAAALBAcAIAAAAACy2a43TJJZc0eTwvL+9I6gIAAAAAbVKLglNUVJTl8WuvvfaIKgQAAAAAbU2LgtPcuXOPVT0AAAAAoM1ijhMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWGjV4DRr1izZbDa/LS0trdHy//rXvzRq1CjFxMQoJiZGo0eP1rfffhvAGgMAAADoiFq9x2ngwIHKyMjwbV988UWjZVesWKHJkydr+fLl+uqrr5SSkqLzzz9fe/fuDWCNAQAAAHQ0wa1egeBgJSYmNqvsa6+95vf43//+t/773//qk08+0bXXXnssqgcAAAAArR+ctmzZouTkZLlcLo0YMUJz5sxRt27dmvXckpISeTwexcbGNlqmvLxc5eXlvscFBQWSJI/HI4/Hc2SVR5Nq2pd2DhzaPPBo88CivQOPNg882jywaO/Aa0tt3pI62AzDMI5hXZq0aNEiFRUVqV+/fsrIyNDs2bO1d+9erVu3ThEREZbPv/XWW7V48WKtX79eLperwTKzZs3S7Nmz6+2fP3++3G73Eb8HAAAAAO1TSUmJrrrqKuXn5ysyMrLJsq0anA6Vl5en7t2764knntANN9zQZNk///nP+stf/qIVK1ZoyJAhjZZrqMcpJSVFWVlZlo2DI+PxeLR06VKdd955cjgcrV2dDoE2DzzaPLBo78CjzQOPNg8s2jvw2lKbFxQUKD4+vlnBqdWH6tUVHR2tvn37auvWrU2We/zxx/XnP/9Zy5YtazI0SZLT6ZTT6ay33+FwtPoPqqOgrQOPNg882jywaO/Ao80DjzYPLNo78NpCm7fk9Vt9Vb26ioqKtG3bNiUlJTVa5i9/+Ysefvhhffzxxzr55JMDWDsAAAAAHVWrBqeZM2fq008/1c6dO/Xll1/q4osvlt1u1+TJkyVJ1157re69915f+UcffVT333+/XnzxRaWmpiozM1OZmZkqKipqrbcAAAAAoANo1aF6e/bs0eTJk5Wdna2EhASdfvrp+vrrr5WQkCBJ2rVrl4KCarPds88+q4qKCl166aV+53nwwQc1a9asQFYdAAAAQAfSqsHpjTfeaPL4ihUr/B7v3Lnz2FUGAAAAABrRpuY4AQAAAEBbRHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAvBrV2BjmxjRoG2HyxWt1i3usW5FRXqaO0qAQAAAGgAwakVffjTPv3f8m2+x1GhDjNEVQcp3/exbiVFuRRsp4MQAAAAaA0Ep1aUGOnSsO4x2pVTooOF5cov9Wjt3nyt3Ztfr2xwkE1dYkL9wlTdgBXhorcKAAAAOFYITq3omhGpumZEqiSppKJSe3JLlZ5dol05JdqdU6L07GLz+9xSVVR6lZ5dovTskgbPFeOu7q2KC1O32JqAFaZucW4lRrpkD7IF8J0BAAAAxxeCUxvhDglW384R6ts5ot4xr9fQ/sIy7aobqnJqv88qqlBuiUe5Jflas6d+b5XDblPXmIZ7qlJi3Qp3chkAAAAATeETczsQFGRTUlSokqJCNbxnXL3jReWV2p1Tt6eq9vvduSXyVBnakVWsHVnFDZ4/LizEb05VSqxbCRFOxYWFKMYdorjwELlDuFQAAADQcfFp+DgQ7gxW/6RI9U+KrHesymsos6Cmt8oc+rcrp9T8ml2s3BKPsosrlF1coR935TX6Gi5HkOLCnIoNC6m3xdV8Da8OWmFORYZyaQEAAOD4wafb45w9yKYu0aHqEh2qEb3q91YVlHnM3qrqXqqaOVXZReXKqQ5UFZVelXm82ptXqr15pc163eAgm2LcDgV77Xpj//eKDXfWBqywEMVWh7CasBXjdrBqIAAAANosglMHF+lyaGBylAYmRzV43DAMFVdUKaeoQjklFcopLld2UYVyiit8wSq3+mvNvqLySlV6DR0sqpBkU8b2HMt62Gzmcuw1wapmiGBsdciKDw9RalyY+naOUGiI/Si3AgAAANA0ghOaZLPZFO4MVrgzWN3i3M16TpmnSrklFTqQX6KPl69U74EnKL+syi9omd+bvVp5pR4ZhpRX4lFeiUfbDzY8F8usj5QaF6Z+nSOUlhShtMQIpSVGqlusW0GsHAgAAIBjhOCEo87lsCspKlTx7mDtjDY0fmiSHI7G7zNV5TWUW+Lfc5VdXGH2chWXK6fEo4OFZdp6oEhZRRW+hS4+Xp/pO0eow66+iRFKqw5U/RIj1D8xUjFhIYF4ywAAADjOEZzQ6uxBNsWHOxUf7lQfi7IHC8u1ObNQmzILtCmzUJszC/Xz/kKVeqq0Znee1uzO8yvfKcKptKTI6p4ps3eqV6cwOYMZ7gcAAIDmIzihXUmIcCohwqnT+8T79lV5De3MLtamjEJtzizQxupAtSunRAcKy3Wg8KA++/mgr7w9yKZeCWHql1gnUCVFKjnKJZuN4X4AAACoj+CEds8MQuHqlRCuC4Yk+fYXlVfq5/2F9QJVfqlHP+8v0s/7i/TBmtrzRLiClZZoDvNLqw5V/RIjFOFqfJghAAAAOgaCE45b4c5gndQtRid1i/HtMwzzvlabMmsD1abMQm07WKTCskp9tzNX3+3M9TtPl+hQ9U/yD1Q94sNYPh0AAKADITihQ7HZbEqKClVSVKjO7tfJt7+i0qvtWUXanFmojXUCVUZ+me/+Vcs2HvCVDwkOUu+EcCVFuRQZ6lCkK7j6q0NRoQ5FhgYr0uXw2xfuCpadlf8AAADaJYITIDMImb1JkbrohNr9+SUebcos0Ob9tYFqc2ahiiuqtCGjQBsyClr0OhHO6oB1SNiKDA02A5fL/1hUnbLhzmDmYAEAALQSghPQhCi3Q8N7xml4zzjfPq/X0N68Um3OLFR2cbkKSitVUOZRfqlHBaUeFZRVVn+t2VepUk+VJKmwvFKF5ZXam1fa4roE2eQXtCJd9Xu4wkKCtC/Hpj4HitSrcySrBwIAABwlBCeghYKCbEqJdSsltnk3BJbMoYCFNUGqTrAqKK2s3lcbumoDmHm8oNSjiiqvvHVuEtw0u/69+UsF2aQuMaHqER+uHnFu9YgPU4+EcPWMD1NydCjDBgEAAFqA4AQEQEhwkOLCnYoLd7b4uYZhqLzSW6cXq27w8g9bOcXl2pi+XzmVwSour9LunFLtzinVZ4fWxx6kbtVhqmd8mBmqqreECCdDAgEAAA5BcALaOJvNJpfDLpfDrk6RribLejweLVy4UOPGna+8cq92ZpVoR1aRtmcVa8fBYu3IKlZ6TokqKr3aeqBIWw8U1TtHWIhdPRLCzJ6q+DD1iHf7vo8KZWl2AADQMRGcgOOQzWZTpwiXOkW4dGqPWL9jVV5D+/JKtSOruN62J7dExRVVWre3QOv21l/4Ii4sRKl1eqd6xoepR0KYUuPC5HIwnwoAABy/CE5AB2OvM0frjL4JfsfKK6u0O6dEO6p7qnZkFWt7dU/VgcJyZRdXKLu4Qj+k59Y7b3KUq7qnygxSPat7rbrGhMrBPa8AAEA7R3AC4OMMtqt3pwj17hQhqbPfsaLySu1soJdq+8EiFZRVal9+mfbll2nl1my/5wUH2ZQcHarkaJeSo0PVJTq0+nGoulTvc4fwqwgAALRtfFoB0CzhzmAN6hKlQV2i/PYbhqHcEk91D5V/T9XO7GKVebzalVOiXTkljZ47xu2oE6ZqQ1bN44Rwp4JYBRAAALQighOAI2Kz2RQbFqLYsFgN6+4/n8rrNZRZUKa9eaXal1eqvXml2ptrfr8vz9xfVF6p3BKPcks8Wr+v4RsKO+w2JUa5lBzl32OVHO3yPQ5z8usMAAAcO3zSAHDMBPmG6YU2WqagzFMdpEq1N6/M931NuMosKJOnyvAtrd6YqFCHL0R1qdNj5eu1inBy7yoAAHDYCE4AWlWky6HIRIfSEiMbPF5Z5dWBwvLaHqs6oapmX2H1vazySz3akNFwr1VwUHWvVXWQSo0L04DkSA1IjlRylIt7VwEAgCYRnAC0acH2IF/P0cmNlCko8yijTpCq22O1N69UmQVlqvQa2pNbqj259XutokIdGpBkhqiB1WGqV0I4qwECAAAfghOAdq+m16pfYkSDx6u8hg4UlvmGA+7NLdWWA4XasK9AWw8UKb/Uo6+2Z+ur7bUrAobYg9Q3MVwDkiI1MDlKA5IjlZYYoQgXNwEGAKAjIjgBOO7Zg2xKigpVUlSohnX3P1ZeWaUt+4u0IaNAG/ZVbxkFKiqvrHMj4D2+8t3j3NVhyuyZ6pPglmEE9v0AAIDAIzgB6NCcwfZ6y6x7q4f1bcjI14Z9BVpfHaYy8suUnl2i9OwSLVqX6SsfFmzXWwe/1+Au0ea8qaRI9YgPUzBD/QAAOG4QnADgEEFBNnWLc6tbnFtjByX59ucUV2hjdc/U+n352pBRoG0Hi1VcKX25LUdfbsvxlXUGByktMUIDqof5DUgyh/qxbDoAAO0T/4MDQDPFhoXotN7xOq13vG9fYUmZ5r27WLE9h2jzgWKt31egjRkFKqmo0po9+VqzJ99X1maTetRZza9mQYpOEa7WeDsAAKAFCE4AcARcDru6hUvjT+4qh8NcOMLrNZSeU1I9XyrfHOq3r0AHCsu1PatY27OK9eFPGb5zxIc7NSA5Uv0TI5QaH6bUuDD1TAhTpwgny6QDANBGEJwA4CgLCrKpR3yYesSH6YIhtUP9DhaWm0P9MqrnTe3L1/asYmUVleuznw/qs58P+p3HHWJXapx5ntR4t3rEh6tHvFupcWGKDQshVAEAEEAEJwAIkIQIpxIiEnRG3wTfvpKKSm3OLNT66qXRd2QVa2d2sfbklqqkospc7a+Bm/pGuoKrA1WYL6TVPI5kyXQAAI46ghMAtCJ3SLBO7BajE7vF+O2vqPRqd26JdmYVa0f1tjO7WDuzSrQ3r1QFZZX15lDViAsLqReqUuPMXit3CL/2AQA4HPwPCgBtUEhwkHolhKtXQni9Y2WeKqVnl2hHVpF2ZNUJV9nFOlhYruziCmUXV+j79Nx6z02MdNUb9tczIUwpsW45g+2BeGsAALRLBCcAaGdcDrv6JUaoX2JEvWNF5ZW+IFU3UO3IKlZeiUeZBWXKLCjT19tz/J4XZJOSo0P9eqh6JISpe6xbSVGhCg0hVAEAOjaCEwAcR8KdwfVu6Fsjr6SidthfVrF2VPda7cwqUVF5pfbklmpPbqk+35JV77nRbocSI11KinIpMSpUyVEuJUa5lBQVWv3VxT2qAADHNf6XA4AOItodohO7hdSbT2UYhrKKKnyBanv1153ZxdqVU6KSiirllXiUV+LRpszCRs8f6Qr2C1JJUaHVQcvl+xrBwhUAgHaK4AQAHZzNZqte8c+pU3vE+h0zDEOF5ZXKyCtTRn6pMvPLlJFfpsz8Mu2rfpyZX6bC8koVlFWqoKxQm/c3Hq4inMFKrBOm/MOVGboiXcEstQ4AaHMITgCARtlsNkW6HIpMdDQ4p6pGYZlH+wvKtC+vrDZcFZQqI7/MF7oKyipVWF6pwgNF2nKgqNFzhYXY6w0DrAlY8WHBKvJIlVVeOei8AgAEEMEJAHDEIlwORbgc6t2p8XBVXF5pLk6RX6Z9edW9VwW1QSsjv1R5JR4VV1Rp28FibTtY3MiZgnXf98sU4QpWVKhD0W6HokNDFBXqUJTboehQh29/VPX+aHfNY4dCHXZ6tAAALUZwAgAERJgzuNEl1muUVlQps8B/WOCh3+cUeyRJhWWVKiwzF7VoiRB7kKKqQ1RNyIqqE75qQlZk9fFot7k/0hWsYHvQEbUBAKD9IjgBANqM0BC7b0n0hng8Hn3w4UKNPHu0SjyG8ko9yi/xKL/Uo7ySCvNx9b6a7/NKKqq/elTpNVRR5dXBwnIdLCxvcf0a6+WKCwtRt1i378bDcWEh9GoBwHGG4AQAaFfsQVJcWIgSWzjJyTAMc4VAX7CqqA1d1cEqv9Sj/NIK3/c1X4vKKyU1v5crwhms1OoQ1SPOre5x1d/HhynG7SBUAUA7RHACAHQINptNYc5ghTmD1SU6tEXP9VR5VVDqOaRHq8LXs3WgsFzp2cXamVWiffmlKiyv1Nq9+Vq7N7/euSJdwb6eqdS4MN/3PeLCFOVmxQsAaKsITgAAWHDYgxQX7lRcuNOybJmnSrtySnz3xdqZXXPT4RJlFpSpoKxSa/bka82e+qEqxu3whajUOoEqNd7NPbAAoJURnAAAOIpcDrv6do5Q3871VxgsrajSzmwzUO3ILlZ6Vol2VD8+UFiu3BKPcnfl6cddefWeGx8eotQ6Q/5SqwNValyYwpz8dw4Axxq/aQEACJDQELv6J0Wqf1JkvWPF5ZXVoaqkTi+V2WOVVVTh275Pz6333E4RTr+eqh7xbvWID1eP+DCFBLMSIAAcDQQnAADagDBnsAYmR2lgclS9YwVlHr/eqZoeq51ZxcotMedYHSgs17c7cvyeFxxkU8+EMPVLjFRaYoT6dY5Qv8QIdY0JZYEKAGghghMAAG1cpMuhwV2jNLhr/VCVX+Lxhagd1T1UO7OKtf1gsQrLK/Xz/iL9vL9IH6ypfU64M1h9O4fXBqrECKUlRijaHRLAdwUA7QvBCQCAdizK7dAJ7midkBLtt98wDO3LL9PmzAJtyizU5upt28EiFZVXatWuPK06ZC5V50in0uqEqX6JEeoe4wrcmwGANozgBADAcchms6lLdKi6RIfqnLTOvv0VlV7tyCrWpswCX5jalFmovXml2l9Qrv0FB/Xpzwd95e1BNsU77VpcuEb9k6Kqe6ci1TUmVEFBDPcD0HEQnBpRVVUlj8fT2tVo1zwej4KDg1VWVqaqqqrWrk6b4HA4ZLfbW7saADqwkOAgX29SXYVlHv28v9DXO1XzNb/Uo/2lNi1ct18L1+33lXeHmKsH1u2dSkuMVGwYw/0AHJ8ITocwDEOZmZnKy8tr7aq0e4ZhKDExUbt372YSch3R0dFKTEykTQC0KREuh4Z1j9Ww7rG+fYZhaE9OkV77YLkiu6dp64ESbcos1NYDRSqpqNLq3XlavTvP7zwJEU6/hSjSEiPVp3O4XA7+aASgfSM4HaImNHXq1Elut5sPt0fA6/WqqKhI4eHhCgpiOVzDMFRSUqIDBw5IkpKSklq5RgDQNJvNpsRIl/rHGBp/eg85HOZNeD1VXu3MKvbvndpfoN05pTpYWK6DheX6fEuW7zxBNik1Lkx9O0eoW5xbyVEuJUeHqkuMOZQwKtTB/7cA2jyCUx1VVVW+0BQXF9fa1Wn3vF6vKioq5HK5CE7VQkNDJUkHDhxQp06dGLYHoF1y2IPUp3OE+nSO0IShtfuLyiv18/7COnOnzHlUuSUebc8q1vas4gbPFxZiV3J0qF+Y6lL9ODnapcRIl4Lt/D8CoHW1anCaNWuWZs+e7bevX79+2rRpU4Pl169frwceeEA//PCD0tPT9eSTT+qOO+44avWpmdPkdruP2jmBQ9VcXx6Ph+AE4LgS7gzWSd1idFK3GN8+wzB0sLBcmzILteVAkfbllWpvbqn25ZdqX16psooqVFxRpS0HirTlQFGD5w2ySYmRtb1UydH+4apLTKjCnfwtGMCx1eq/ZQYOHKhly5b5HgcHN16lkpIS9ezZU5dddpl++9vfHrM6MVwAxxLXF4COxGazqVOkS50iXTqjb0K942WeKjNM5ZVWfy0zg1VebbjyVJlLq+/LL9P36bkNvk6kK1jJ0aHqWidY1fRidY0JVUK4k1UAARyRVg9OwcHBSkxMbFbZU045Raeccook6Z577mnWc8rLy1VeXu57XFBQIMn8a/+hq+Z5PB4ZhiGv1yuv19us86NxhmH4vtKetbxerwzDOCY9TjXXNCtCBg5tHli0d+Ad6za3S0qJdiol2ikput5xr9dQVnGF9uaVKiPPDE9mqCrTvrwy7csvVX5ppQrKKlVQPd+qIQ67rbrXyuWbY5Uc5VJSlEuxYSGKCnUoKjRY4c7gVv8DF9d5YNHegdeW2rwldWj14LRlyxYlJyfL5XJpxIgRmjNnjrp163bUzj9nzpx6wwElacmSJfWG5NWEuKKiIlVUVBy1OrRXQ4YM0S233KJbbrmlWeW/+OILTZgwQTt37lRUVO3d7QsLG/5PrKOqqKhQaWmpPvvsM1VWVh6T11i6dOkxOS8aR5sHFu0deG2lzZMlJQdJiqneJJVVSbnlUm65TbkVUk65TbnlUl65TTnlUn6F5KmSdueWanduaZPnD5Kh0GDJ7dsMhdqlsGBV7zf8jrnrlHUc5WlYbaXNOwraO/DaQpuXlJQ0u6zNqOkWaAWLFi1SUVGR+vXrp4yMDM2ePVt79+7VunXrFBER0eRzU1NTdccdd1jOcWqoxyklJUVZWVmKjIz0K1tWVqbdu3crNTVVLlf7uVO6Va/FAw88oAcffLDF5z148KDCwsKaPeeroqJCOTk56ty5s2w2mwzDUGFhoSIiIo7qX+9WrFihc889V9nZ2YqOjj5q5w2UsrIy7dy5UykpKUf9OvN4PFq6dKnOO+883+pXOLZo88CivQPveGjzyiqvDhSW1/ZS1fRY5ZcpM79MeSUe5Zd5VOY5stERzuAgRYc6FBXqUGRosKJDHYoMddT5GnzIY7NcpMshe51hhMdDm7cntHfgtaU2LygoUHx8vPLz8+tlg0O1ao/TuHHjfN8PGTJEw4cPV/fu3fXWW2/phhtuOCqv4XQ65XQ66+13OBz1flBVVVWy2WwKCgpqV6vAZWRk+L5/88039cADD2jz5s2+fXWXAzcMQ1VVVU3OJavRuXNnyzJ1uVwuJScn+x7XDM+radOjpeZc7e3nVCMoKEg2m63Ba/BoOZbnRsNo88CivQOvPbe5wyF1dznVPaHpD0VlnioVlHqUV+oxw1SpR3klFcov9fg23/5Sj1m2+rjXkMorvdpfWK79heVNvk5DIlzBinZXhy5XsKoKgpQetls9O0Woe2yYusW5FRXaPtu/vWjP13h71RbavCWv3+pD9eqKjo5W3759tXXr1tauio9hGCr1VLXKa4c67M3qqak7RywqKsq870b1vhUrVujss8/WwoUL9Yc//EFr167VkiVLlJKSojvvvFNff/21iouL1b9/f82ZM0ejR4/2nevQXj2bzaZ//etf+uijj7R48WJ16dJFf/3rX3XhhRf6vVZubq6io6M1b948/fa3v9Ubb7yhO++8U7t379bpp5+uuXPn+u5hVFlZqTvvvFMvv/yy7Ha7brzxRmVmZio/P18LFiw4rHbLzc3Vb37zG33wwQcqLy/XmWeeqX/84x/q06ePJCk9PV0zZszQF198oYqKCqWmpuqxxx7T+PHjlZubqxkzZmjJkiUqKipS165d9fvf/17XXXfdYdUFANB+uBx2uRx2dYps2WgAr9dQUUWl8ksODVfVoave/trQVVxhfsYoLKtUYVmldqtmKGGQvlnm/3ko2u1Q91i3usWFVX91KzUuTN3j3OoU4Wz1uVnA8a5NBaeioiJt27ZN11xzTWtXxafUU6UBDyxuldfe8NAYuUOOzo/onnvu0eOPP66ePXsqJiZGu3fv1vjx4/XHP/5RTqdTL7/8siZMmKDNmzc3Ocds9uzZ+stf/qLHHntMTz31lKZMmaL09HTFxsY2WL60tFR//etf9corrygoKEhXX321Zs6cqddee02S9Oijj+q1117T3Llz1b9/f/3973/XggULdPbZZx/2e502bZq2bNmi999/X5GRkbr77rs1fvx4bdiwQQ6HQ9OnT1dFRYU+++wzhYWFacOGDQoPD5ck3X///dqwYYMWLVqk+Ph4bd26VaWlTY+HBwB0bEFBNkW6HIp0OZTSwud6qryH9GZVKKugTP/7do1ccV21O69M6dklyioqV16JR3kl+VqzJ7/eeVyOIHWLdatbrBmkuse51S3Wre5xYeoaEyoH98ECjlirBqeZM2dqwoQJ6t69u/bt26cHH3xQdrtdkydPliRde+216tKli+bMmSPJnEOzYcMG3/d79+7V6tWrFR4ert69e7fa+2gPHnroIZ133nm+x7GxsRo6tPauhQ8//LDeffddvf/++5oxY0aj55k2bZrv5/OnP/1J//jHP/Ttt99q7NixDZb3eDx69tlnfb09M2bM0EMPPeQ7/tRTT+nee+/VxRdfLEl6+umntXDhwsN+nzWBaeXKlRo5cqQk6bXXXlNKSooWLFigyy67TLt27dKkSZM0ePBgSVLPnj19z9+1a5dOPPFEnXzyyZLMXjcAAI4Vhz1I8eFOxYfXTivweDxyZqzW+PGDfcOIissrtSunROnZJUrPLlZ6Tol2ZZcoPadYe3NLVebx6uf9Rfp5f/17YdmDbEqOdvmG/HWPrQlWZsgK4x5YQLO06r+UPXv2aPLkycrOzlZCQoJOP/10ff3110pIMO/zsGvXLr85LPv27dOJJ57oe/z444/r8ccf15lnnqkVK1YckzqGOuza8NCYY3Lu5rz20VITBGoUFRVp1qxZ+uijj5SRkaHKykqVlpZq165dTZ5nyJAhvu/DwsIUGRmpAwcONFre7XarV69evsdJSUm+8vn5+dq/f79OPfVU33G73a5hw4Yd9vLlGzduVHBwsIYPH+7bFxcXp379+mnjxo2SpNtvv1233HKLlixZotGjR2vSpEm+93XLLbdo0qRJWrVqlc4//3xNnDjRF8AAAGgtYc5g9U+KVP+k+vO0PFVe7c0trQ5TxdqZbQasXTnF2pVTojKPV7tzSrU7p1RqYDZEfHiIusWaw/66xfmHqriwEIYAAtVaNTi98cYbTR4/NAylpqYq0IsA2my2ozZcrjWFhYX5PZ45c6aWLl2qxx9/XL1791ZoaKguvfRSy2XYD51AZ7PZmgw5hy5CUbPaXmu68cYbNWbMGH300UdasmSJ5syZo7/+9a+67bbbNG7cOKWnp2vhwoVaunSpzj33XE2fPl2PP/54q9YZAIDGOOxBSo0PU2p8mCT/mwwbhqEDheW+nqpDe63ySjzKKqpQVlGFVu3Kq3fusBC7b05Vp0inot0hinE7FOMOUXT119gw8/u2cA8s4Fhq/4kAh2XlypWaNm2ab4hcUVGRdu7cGdA6REVFqXPnzvruu+90xhlnSDJXNly1apVOOOGEwzpn//79VVlZqW+++cbXU5Sdna3NmzdrwIABvnIpKSm6+eabdfPNN+vee+/Vv/71L912222SpISEBE2dOlVTp07VqFGj9Lvf/Y7gBABol2w2mzpHutQ50qVTe9Sfj5xf6vEN+UvPrh3+tyu7RBkFZSquqNLGjAJtzCiwfC2H3aaoUP9gZYaqQ8JWWO3jqFCHgpl/hXaC4NRB9enTR++8844mTJggm82m+++//7CHxx2J2267TXPmzFHv3r2Vlpamp556Srm5uc36i9XatWv97vdls9k0dOhQXXTRRfrVr36l559/XhEREbrnnnvUpUsXXXTRRZKkO+64Q+PGjVPfvn2Vm5ur5cuXq3///pLMe14NGzZMAwcOVHl5uT788EPfMQAAjjdRoQ4N7hqlwV2j6h0r81RpT27NsL8SZRdVKLekQnklHuWWVCi3xKPcYnNfeaVXnipDWUXlyipq2XLska5gxRwSsGKqv48Oq9/DFeMOUWjI0ZvOADQXwamDeuKJJ3T99ddr5MiRio+P1913362CAuu/Jh1td999tzIzM3XttdfKbrfrpptu0pgxYyxv6ivJ10tVw263q7KyUnPnztVvfvMb/fKXv1RFRYXOOOMMLVy40DfMsKqqStOnT9eePXsUGRmpsWPH6sknn5QkhYSE6N5779XOnTsVGhqqUaNGWQ4pBQDgeORy2NW7U4R6d4qwLFtaUVUdphoOVnX35ZVUKLe4QgVllZKkgrJKFZRVKj27pAV1C1KM25yb1T8pUgOq53/16Rwu11GcIw7UZTNae8JJgBUUFCgqKqrBuwOXlZVpx44d6tGjh1yult3DAfV5vV4VFBQoMjKy2Teq9Xq96t+/vy6//HI9/PDDx7iGreNYXmcej0cLFy7U+PHjW/2Gch0FbR5YtHfg0eaB11HavLLKW32z4dqQ1ZzQVelt/KOrPcimnvFhvoU0+idFaEBSpBKauM9VR2nvtqQttXlT2eBQ9DihVaWnp2vJkiU688wzVV5erqefflo7duzQVVdd1dpVAwAAx1BwA0uxWzEMQ0Xllcot9ii7uFzbDhb75mBtzChQbolHWw4UacuBIr2/Zp/veXFhIb4gVROqencK5/5WaBGCE1pVUFCQ5s2bp5kzZ8owDA0aNEjLli1jXhEAAKjHZrMpwuVQhMuhbnFundgtxnfMMAztLyjXxowCbagTpnZkFSu7uEJfbM3SF1uzfOUddpt6d4pQWucwGbk2RW/L1uCUWMWGhbTGW0M7QHBCq0pJSdHKlStbuxoAAKCds9lsSoxyKTHKpbPTOvn2l1ZU6ef9hX5halNGoQrLK+usGGjXgnk/SJISI11+PVP9kyLVIz5M9iCWWu/oCE4AAAA4boWG2DU0JVpDU6J9+wzD0J7cUm3IKND6PXlasWaLco0w7c4tVWZBmTILyrR880FfeZcjSP06+4eptKQIRbqYE9WREJwAAADQodhsNqXEupUS69Y5fePUq2yzxo8fpbIqaXNmYfVwP/Pr5sxClXqqtGZPvtbsyfc7T9eYUF+QGlDdS5UQ4VSQzSabTQqy2ao3cXPg4wDBCQAAAJAU4XLo5NRYnZxae7PgKq+h9OxibawOUjXbvvwy7ckt1Z7cUi3dsL9Z568NU2aQCqoTrmw2ySYpKMjWYBmbqh8H+T+n5phfWAuqeWw+Py7MqcFdojSka5QGdYlSQkTzF+RALYITAAAA0Ah7kE09E8LVMyFcFwxJ8u3PK6nQxgz/uVNb9heposrb6LkMQ6oyDFWZj4553etatrE23CVFuTSoS5SGdInSoK5RGtwlqkWrG3ZUBCcAAACghaLdIRrRK04jesX59lVWeVVR5ZXXMOdR1f3qNQx5DUNG9feHfvX6Htfsq/8cb53nNPe8VV5Du3NLtW5vvn7ak6ftWcXKyC9TRn6ZX09ZcpRLg6tD1OCu0RrcJYoVBg9BcAIAAACOgmB7kILb+L2hisortWFfgX7ak2eGqb352pFVrH35ZdqXX6bF62vDVJfo0OogVR2oukQppgOHKYITfM466yydcMIJ+tvf/iZJSk1N1R133KE77rij0efYbDa9++67mjhx4hG99tE6DwAAABoX7gzWqT1idWqP2nlchWUerd9XUN0rla91e/O1PatYe/NKtTevVB+vz/SV7RpTP0xFuztGmCI4HQcmTJggj8ejjz/+uN6xzz//XGeccYbWrFmjIUOGtOi83333ncLCwo5WNSVJs2bN0oIFC7R69Wq//RkZGYqJiWn4SUfJvHnzdMcddygvL++Yvg4AAEB7EuFy6Bc94/SLnrXDDgvKPFq/t0Br9+Zp7d4Crd2Tp53ZJb4FMRatqw1TKbGhGtIl2pw31TVKg5KjFOU+/pZqJzgdB2644QZNmjRJe/bsUdeuXf2OzZ07VyeffHKLQ5MkJSQkHK0qWkpMTAzYawEAAKBpkS5HvTlc+aUerd+br7V1tvTsEu3OKdXunFJ9tDbDV7Z7nFuDqnukhnSJ0sAuUYoKbd9hqm0PwmwLDEOqKG6dzWjeaiu//OUvlZCQoHnz5vntLyoq0ttvv60bbrhB2dnZmjx5srp06SK3263Bgwfr9ddfb/K8qampvmF7krRlyxadccYZcrlcGjBggJYuXVrvOXfffbf69u0rt9ut3r17649//KM8Ho8ks8dn9uzZWrNmjWzVS2TW1Nlms2nBggW+86xdu1bnnHOOQkNDFRcXp5tuuklFRUW+49OmTdPEiRP1+OOPKykpSXFxcZo+fbrvtQ7Hrl27dNFFFyk8PFyRkZG6/PLLtX9/7TjfNWvW6Oyzz1ZERIQiIyM1bNgwff/995Kk9PR0TZgwQTExMQoLC9PAgQO1cOHCw64LAABAWxMV6tDI3vH69Zm99PRVJ+nT352tNQ+cr9duHK57xqXpgsFJ6hbrliSlZ5foo58y9OdFm3TVv7/R0NlLdNZjyzVj/ir9+4ud2pJvU5mnqpXfUcvQ42TFUyL9Kbl1Xvv3+6QQ66FywcHBuvbaazVv3jzdd999vhusvf3226qqqtLkyZNVVFSkYcOG6e6771ZkZKQ++ugjXXPNNerVq5dOPfVUy9fwer265JJL1LlzZ33zzTfKz89vcO5TRESE5s2bp+TkZK1Zs0Y33XST4uPjdffdd+uKK67QunXr9PHHH2vZsmWSpKioqHrnKC4u1pgxYzRixAh99913OnDggG688UbNmDHDLxwuX75cSUlJWr58ubZu3aorrrhCJ5xwgn71q19Zvp+G3l9NaPr0009VWVmp6dOn64orrtCKFSskSVOmTNGJJ56oZ599Vna7XatXr5bDYf7lZPr06aqoqNBnn32msLAwbdiwQeHh4S2uBwAAQHsS5XbotN7xOq13vG9fXkmF1u0t0E9783zzpvbklmpndol2Zpfow58yJNn1y7wypbldrVf5FiI4HSeuv/56PfbYY/r000911llnSTKH6U2aNElRUVGKiorSzJkzfeVvu+02LV68WG+99VazgtOyZcu0adMmLV68WMnJZpD805/+pHHjxvmV+8Mf/uD7vlu3bpoxY4befvtt3X333QoNDVV4eLiCg4ObHJo3f/58lZWV6eWXX/bNsXr66ac1YcIEPfroo+rcubMkKSYmRk8//bTsdrvS0tJ0wQUX6JNPPjms4PTJJ59o7dq12rFjh1JSUiRJL7/8sgYOHKjvvvtOp5xyinbt2qXf/e53SktLkyT16dPH9/xdu3Zp0qRJGjx4sCSpZ8+eLa4DAADA8SDaHaLT+8Tr9D61YSq3uMI3vO+n3blas2O/esS5W7GWLUdwsuJwmz0/rfXazZSWlqaRI0fqxRdf1FlnnaWtW7fq888/10MPPSRJqqqq0p/+9Ce99dZb2rt3ryoqKlReXi63u3mvsXHjRqWkpPhCkySNGDGiXrk333xT//jHP7Rt2zYVFRWpsrJSkZGRzX4fNa81dOhQv4UpTjvtNHm9Xm3evNkXnAYOHCi73e4rk5SUpLVr17boteq+ZkpKii80SdKAAQMUHR2tjRs36pRTTtGdd96pG2+8Ua+88opGjx6tyy67TL169ZIk3X777brlllu0ZMkSjR49WpMmTTqseWUAAADHo5iwEJ3RN0Fn9E2Qx+PRwoULFRRka+1qtQhznKzYbOZwudbYbC27mG644Qb997//VWFhoebOnatevXrpzDPPlCQ99thj+vvf/667775by5cv1+rVqzVmzBhVVFQctab66quvNGXKFI0fP14ffvihfvjhB911111H9TXqqhkmV8Nms8nrbfxu3Udq1qxZWr9+vS644AL973//04ABA/Tuu+9Kkm688UZt375d11xzjdauXauTTz5ZTz311DGrCwAAAAKL4HQcufzyyxUUFKT58+fr5Zdf1vXXX++b77Ry5UpddNFFuvrqqzV06FD17NlTP//8c7PP3b9/f+3evVsZGbWrpXz99dd+Zb788kt1795d9913n04++WT16dNHu3fv9isTEhKiqqqmJwL2799fa9asUXFxsW/fypUrFRQUpH79+jW7zi1R8/7q1nfDhg3Ky8vTgAEDfPv69u2r3/72t1qyZIkuueQSzZ0713csJSVFN998s9555x3ddddd+te//nVM6goAAIDAIzgdR8LDw3XFFVfo3nvvVUZGhqZNm+Y71qdPHy1dulRffvmlNm7cqF//+td+K8ZZGT16tPr27aupU6dqzZo1+vzzz3Xffff5lenTp4927dqlN954Q9u2bdNTTz2lDz/80K9MamqqduzYodWrVysrK0vl5eX1XmvKlClyuVyaOnWq1q1bp+XLl+u2227TNddc4xumd7iqqqq0evVqv23jxo0aPXq0Bg8erClTpmjVqlX69ttvde211+rMM8/UySefrNLSUs2YMUMrVqxQenq6Vq5cqe+++079+/eXJN1xxx1avHixduzYoVWrVmn58uW+YwAAAGj/CE7HmRtuuEG5ubkaM2aM33ykP/zhDzrppJM0ZswYnXXWWUpMTNTEiRObfd6goCC9++67Ki0t1amnnqobb7xRf/zjH/3KXHjhhfrtb3+rGTNm6IQTTtCXX36p3/3ud35lJk2apLFjx+rss89WQkJCg0uiu91uLV68WDk5OTrllFN06aWX6txzz9XTTz/dssZoQFFRkU488US/bcKECbLZbHrvvfcUExOjM844Q6NHj1bPnj315ptvSpLsdruys7N17bXXqm/fvrr88ss1btw4zZ49W5IZyKZPn67+/ftr7Nix6tu3r5555pkjri8AAADaBpthNPNmQceJgoICRUVFKT8/v96iBWVlZdqxY4d69Oghl6v9LI3YVnm9XhUUFCgyMlJBQWT0GsfyOquZbDl+/Ph6c8BwbNDmgUV7Bx5tHni0eWDR3oHXltq8qWxwKD7NAgAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4NaCDrZeBAOP6AgAAaH8ITnXUrOpRUlLSyjXB8azm+mrtVWQAAADQfMGtXYG2xG63Kzo6WgcOHJBk3k/IZrO1cq3aL6/Xq4qKCpWVlbEcucyeppKSEh04cEDR0dGy2+2tXSUAAAA0E8HpEImJiZLkC084fIZhqLS0VKGhoQTQOqKjo33XGQAAANoHgtMhbDabkpKS1KlTJ3k8ntauTrvm8Xj02Wef6YwzzmBYWjWHw0FPEwAAQDtEcGqE3W7nA+4RstvtqqyslMvlIjgBAACgXWPiCQAAAABYIDgBAAAAgAWCEwAAAABY6HBznGpuPlpQUNDKNTn+eTwelZSUqKCggDlOAUKbBx5tHli0d+DR5oFHmwcW7R14banNazJBTUZoSocLToWFhZKklJSUVq4JAAAAgLagsLBQUVFRTZaxGc2JV8cRr9erffv2KSIignsLHWMFBQVKSUnR7t27FRkZ2drV6RBo88CjzQOL9g482jzwaPPAor0Dry21uWEYKiwsVHJysoKCmp7F1OF6nIKCgtS1a9fWrkaHEhkZ2er/KDoa2jzwaPPAor0DjzYPPNo8sGjvwGsrbW7V01SDxSEAAAAAwALBCQAAAAAsEJxwzDidTj344INyOp2tXZUOgzYPPNo8sGjvwKPNA482DyzaO/Daa5t3uMUhAAAAAKCl6HECAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHDCYZkzZ45OOeUURUREqFOnTpo4caI2b97c5HPmzZsnm83mt7lcrgDVuP2bNWtWvfZLS0tr8jlvv/220tLS5HK5NHjwYC1cuDBAtT0+pKam1mtzm82m6dOnN1iea7xlPvvsM02YMEHJycmy2WxasGCB33HDMPTAAw8oKSlJoaGhGj16tLZs2WJ53v/7v/9TamqqXC6Xhg8frm+//fYYvYP2p6k293g8uvvuuzV48GCFhYUpOTlZ1157rfbt29fkOQ/nd1NHYnWdT5s2rV77jR071vK8XOeNs2rzhn6v22w2PfbYY42ek+u8cc35TFhWVqbp06crLi5O4eHhmjRpkvbv39/keQ/3/4BjieCEw/Lpp59q+vTp+vrrr7V06VJ5PB6df/75Ki4ubvJ5kZGRysjI8G3p6ekBqvHxYeDAgX7t98UXXzRa9ssvv9TkyZN1ww036Mcff9TEiRM1ceJErVu3LoA1bt++++47v/ZeunSpJOmyyy5r9Dlc481XXFysoUOH6v/+7/8aPP6Xv/xF//jHP/Tcc8/pm2++UVhYmMaMGaOysrJGz/nmm2/qzjvv1IMPPqhVq1Zp6NChGjNmjA4cOHCs3ka70lSbl5SUaNWqVbr//vu1atUqvfPOO9q8ebMuvPBCy/O25HdTR2N1nUvS2LFj/drv9ddfb/KcXOdNs2rzum2dkZGhF198UTabTZMmTWryvFznDWvOZ8Lf/va3+uCDD/T222/r008/1b59+3TJJZc0ed7D+T/gmDOAo+DAgQOGJOPTTz9ttMzcuXONqKiowFXqOPPggw8aQ4cObXb5yy+/3Ljgggv89g0fPtz49a9/fZRr1nH85je/MXr16mV4vd4Gj3ONHz5Jxrvvvut77PV6jcTEROOxxx7z7cvLyzOcTqfx+uuvN3qeU0891Zg+fbrvcVVVlZGcnGzMmTPnmNS7PTu0zRvy7bffGpKM9PT0Rsu09HdTR9ZQm0+dOtW46KKLWnQervPma851ftFFFxnnnHNOk2W4zpvv0M+EeXl5hsPhMN5++21fmY0bNxqSjK+++qrBcxzu/wHHGj1OOCry8/MlSbGxsU2WKyoqUvfu3ZWSkqKLLrpI69evD0T1jhtbtmxRcnKyevbsqSlTpmjXrl2Nlv3qq680evRov31jxozRV199dayreVyqqKjQq6++quuvv142m63RclzjR8eOHTuUmZnpdw1HRUVp+PDhjV7DFRUV+uGHH/yeExQUpNGjR3PdH6b8/HzZbDZFR0c3Wa4lv5tQ34oVK9SpUyf169dPt9xyi7Kzsxsty3V+dO3fv18fffSRbrjhBsuyXOfNc+hnwh9++EEej8fvmk1LS1O3bt0avWYP5/+AQCA44Yh5vV7dcccdOu200zRo0KBGy/Xr108vvvii3nvvPb366qvyer0aOXKk9uzZE8Datl/Dhw/XvHnz9PHHH+vZZ5/Vjh07NGrUKBUWFjZYPjMzU507d/bb17lzZ2VmZgaiusedBQsWKC8vT9OmTWu0DNf40VNznbbkGs7KylJVVRXX/VFSVlamu+++W5MnT1ZkZGSj5Vr6uwn+xo4dq5dfflmffPKJHn30UX366acaN26cqqqqGizPdX50vfTSS4qIiLAcNsZ13jwNfSbMzMxUSEhIvT/ANHXNHs7/AYEQ3GqvjOPG9OnTtW7dOsuxviNGjNCIESN8j0eOHKn+/fvr+eef18MPP3ysq9nujRs3zvf9kCFDNHz4cHXv3l1vvfVWs/5ShiPzwgsvaNy4cUpOTm60DNc4jhcej0eXX365DMPQs88+22RZfjcdmSuvvNL3/eDBgzVkyBD16tVLK1as0LnnntuKNesYXnzxRU2ZMsVyIR+u8+Zp7mfC9ooeJxyRGTNm6MMPP9Ty5cvVtWvXFj3X4XDoxBNP1NatW49R7Y5v0dHR6tu3b6Ptl5iYWG/Fmv379ysxMTEQ1TuupKena9myZbrxxhtb9Dyu8cNXc5225BqOj4+X3W7nuj9CNaEpPT1dS5cubbK3qSFWv5vQtJ49eyo+Pr7R9uM6P3o+//xzbd68ucW/2yWu84Y09pkwMTFRFRUVysvL8yvf1DV7OP8HBALBCYfFMAzNmDFD7777rv73v/+pR48eLT5HVVWV1q5dq6SkpGNQw+NfUVGRtm3b1mj7jRgxQp988onfvqVLl/r1iKB55s6dq06dOumCCy5o0fO4xg9fjx49lJiY6HcNFxQU6Jtvvmn0Gg4JCdGwYcP8nuP1evXJJ59w3TdTTWjasmWLli1bpri4uBafw+p3E5q2Z88eZWdnN9p+XOdHzwsvvKBhw4Zp6NChLX4u13ktq8+Ew4YNk8Ph8LtmN2/erF27djV6zR7O/wEB0WrLUqBdu+WWW4yoqChjxYoVRkZGhm8rKSnxlbnmmmuMe+65x/d49uzZxuLFi41t27YZP/zwg3HllVcaLpfLWL9+fWu8hXbnrrvuMlasWGHs2LHDWLlypTF69GgjPj7eOHDggGEY9dt75cqVRnBwsPH4448bGzduNB588EHD4XAYa9euba230C5VVVUZ3bp1M+6+++56x7jGj0xhYaHx448/Gj/++KMhyXjiiSeMH3/80beC25///GcjOjraeO+994yffvrJuOiii4wePXoYpaWlvnOcc845xlNPPeV7/MYbbxhOp9OYN2+esWHDBuOmm24yoqOjjczMzIC/v7aoqTavqKgwLrzwQqNr167G6tWr/X63l5eX+85xaJtb/W7q6Jpq88LCQmPmzJnGV199ZezYscNYtmyZcdJJJxl9+vQxysrKfOfgOm8Zq98thmEY+fn5htvtNp599tkGz8F13nzN+Ux48803G926dTP+97//Gd9//70xYsQIY8SIEX7n6devn/HOO+/4Hjfn/4BAIzjhsEhqcJs7d66vzJlnnmlMnTrV9/iOO+4wunXrZoSEhBidO3c2xo8fb6xatSrwlW+nrrjiCiMpKckICQkxunTpYlxxxRXG1q1bfccPbW/DMIy33nrL6Nu3rxESEmIMHDjQ+OijjwJc6/Zv8eLFhiRj8+bN9Y5xjR+Z5cuXN/h7pKZNvV6vcf/99xudO3c2nE6nce6559b7OXTv3t148MEH/fY99dRTvp/Dqaeeanz99dcBekdtX1NtvmPHjkZ/ty9fvtx3jkPb3Op3U0fXVJuXlJQY559/vpGQkGA4HA6je/fuxq9+9at6AYjrvGWsfrcYhmE8//zzRmhoqJGXl9fgObjOm685nwlLS0uNW2+91YiJiTHcbrdx8cUXGxkZGfXOU/c5zfk/INBshmEYx6YvCwAAAACOD8xxAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgCgCTabTQsWLGjtagAAWhnBCQDQZk2bNk02m63eNnbs2NauGgCggwlu7QoAANCUsWPHau7cuX77nE5nK9UGANBR0eMEAGjTnE6nEhMT/baYmBhJ5jC6Z599VuPGjVNoaKh69uyp//znP37PX7t2rc455xyFhoYqLi5ON910k4qKivzKvPjiixo4cKCcTqeSkpI0Y8YMv+NZWVm6+OKL5Xa71adPH73//vu+Y7m5uZoyZYoSEhIUGhqqPn361At6AID2j+AEAGjX7r//fk2aNElr1qzRlClTdOWVV2rjxo2SpOLiYo0ZM0YxMTH67rvv9Pbbb2vZsmV+wejZZ5/V9OnTddNNN2nt2rV6//331bt3b7/XmD17ti6//HL99NNPGj9+vKZMmaKcnBzf62/YsEGLFi3Sxo0b9eyzzyo+Pj5wDQAACAibYRhGa1cCAICGTJs2Ta+++qpcLpff/t///vf6/e9/L5vNpptvvlnPPvus79gvfvELnXTSSXrmmWf0r3/9S3fffbd2796tsLAwSdLChQs1YcIE7du3T507d1aXLl103XXX6ZFHHmmwDjabTX/4wx/08MMPSzLDWHh4uBYtWqSxY8fqwgsvVHx8vF588cVj1AoAgLaAOU4AgDbt7LPP9gtGkhQbG+v7fsSIEX7HRowYodWrV0uSNm7cqKFDh/pCkySddtpp8nq92rx5s2w2m/bt26dzzz23yToMGTLE931YWJgiIyN14MABSdItt9yiSZMmadWqVTr//PM1ceJEjRw58rDeKwCg7SI4AQDatLCwsHpD546W0NDQZpVzOBx+j202m7xeryRp3LhxSk9P18KFC7V06VKde+65mj59uh5//PGjXl8AQOthjhMAoF37+uuv6z3u37+/JKl///5as2aNiouLfcdXrlypoKAg9evXTxEREUpNTdUnn3xyRHVISEjQ1KlT9eqrr+pvf/ub/vnPfx7R+QAAbQ89TgCANq28vFyZmZl++4KDg30LMLz99ts6+eSTdfrpp+u1117Tt99+qxdeeEGSNGXKFD344IOaOnWqZs2apYMHD+q2227TNddco86dO0uSZs2apZtvvlmdOnXSuHHjVFhYqJUrV+q2225rVv0eeOABDRs2TAMHDlR5ebk+/PBDX3ADABw/CE4AgDbt448/VlJSkt++fv36adOmTZLMFe/eeOMN3XrrrUpKStLrr7+uAQMGSJLcbrcWL16s3/zmNzrllFPkdrs1adIkPfHEE75zTZ06VWVlZXryySc1c+ZMxcfH69JLL212/UJCQnTvvfdq586dCg0N1ahRo/TGG28chXcOAGhLWFUPANBu2Ww2vfvuu5o4cWJrVwUAcJxjjhMAAAAAWCA4AQAAAIAF5jgBANotRpsDAAKFHicAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAAL/x+KLsYpjwIwGwAAAABJRU5ErkJggg=="},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"sample_eng_sentence = \"<start> And by the night when it covers up <end>\"\n\ntranslated_to_urdu = translate_sentence(\n    input_sentence=sample_eng_sentence,\n    input_sp_model=sp_eng,\n    target_sp_model=sp_urdu,\n    translation_model=transformer,\n    max_length=100\n)\n\nprint(\"Translated to Urdu:\", translated_to_urdu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T20:16:40.248268Z","iopub.execute_input":"2024-11-16T20:16:40.248688Z","iopub.status.idle":"2024-11-16T20:16:41.184250Z","shell.execute_reply.started":"2024-11-16T20:16:40.248648Z","shell.execute_reply":"2024-11-16T20:16:41.183321Z"}},"outputs":[{"name":"stdout","text":"Input tensor: [[8907    3 1420   15  188    8  620  148   89 3510  157  778 8907    4\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 7730, 7730, 7730, 17, 15, 15, 15, 15, 15, 32, 3, 7730, 3]\nTranslated to Urdu: <end>      و اور اور اور اور اور تم<start> <start>\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"sample_eng_sentence = \"<start> So , never should you be strict with any orphan <end>\"\n\ntranslated_to_urdu = translate_sentence(\n    input_sentence=sample_eng_sentence,\n    input_sp_model=sp_eng,\n    target_sp_model=sp_urdu,\n    translation_model=transformer,\n    max_length=100\n)\n\nprint(\"Translated to Urdu:\", translated_to_urdu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T20:17:00.273748Z","iopub.execute_input":"2024-11-16T20:17:00.274185Z","iopub.status.idle":"2024-11-16T20:17:01.309321Z","shell.execute_reply.started":"2024-11-16T20:17:00.274149Z","shell.execute_reply":"2024-11-16T20:17:01.308252Z"}},"outputs":[{"name":"stdout","text":"Input tensor: [[8907    3 1420   92  599  450   31   39 5349   99  182 1752  778 8907\n     4    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 20, 20, 6, 6, 6, 6, 6, 6, 32, 144, 134, 3, 7730, 3]\nTranslated to Urdu: <end>   کی کی ک ک ک ک ک ک تم یا اگر<start> <start>\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"sample_eng_sentence = \"<start> In th name of allah <end>\"\n\ntranslated_to_urdu = translate_sentence(\n    input_sentence=sample_eng_sentence,\n    input_sp_model=sp_eng,\n    target_sp_model=sp_urdu,\n    translation_model=transformer,\n    max_length=100\n)\n\nprint(\"Translated to Urdu:\", translated_to_urdu)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T20:26:10.700393Z","iopub.execute_input":"2024-11-16T20:26:10.701272Z","iopub.status.idle":"2024-11-16T20:26:11.435787Z","shell.execute_reply.started":"2024-11-16T20:26:10.701230Z","shell.execute_reply":"2024-11-16T20:26:11.434842Z"}},"outputs":[{"name":"stdout","text":"Input tensor: [[8907    3 1420   42  221 1417   28   56  778 8907    4    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0]]\nTranslated tokens: [4, 7730, 7730, 324, 20, 114, 6, 6, 6, 81, 3, 7730, 3]\nTranslated to Urdu: <end>   بڑی کی رب ک ک ک آپ<start> <start>\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"sample_eng_sentence = \"<start> In the name of Allah. <end>\"\n\ntranslated_to_urdu = translate_sentence(\n    input_sentence=sample_eng_sentence,\n    input_sp_model=sp_eng,\n    target_sp_model=sp_urdu,\n    translation_model=transformer,\n    max_length=50\n)\n\nprint(\"Translated to Urdu:\", translated_to_urdu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T20:25:52.307283Z","iopub.execute_input":"2024-11-16T20:25:52.307681Z","iopub.status.idle":"2024-11-16T20:25:54.730808Z","shell.execute_reply.started":"2024-11-16T20:25:52.307644Z","shell.execute_reply":"2024-11-16T20:25:54.729537Z"}},"outputs":[{"name":"stdout","text":"Input tensor: [[8907    3 1420   42    8 1417   28   56  778 8907    4    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0]]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_eng_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<start> In the name of Allah. <end>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m translated_to_urdu \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_sentence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_eng_sentence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_sp_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msp_eng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sp_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msp_urdu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtranslation_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated to Urdu:\u001b[39m\u001b[38;5;124m\"\u001b[39m, translated_to_urdu)\n","Cell \u001b[0;32mIn[33], line 33\u001b[0m, in \u001b[0;36mtranslate_sentence\u001b[0;34m(input_sentence, input_sp_model, target_sp_model, translation_model, max_length)\u001b[0m\n\u001b[1;32m     28\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences(\n\u001b[1;32m     29\u001b[0m     [target_sequence], maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Predict the next token\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtranslation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m next_token \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(target_sequence) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Append the predicted token to the target sequence\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node transformer_1/decoder__1/pos_emb_1_1/add defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,50,512] vs. [1,100,512]\n\t [[{{node transformer_1/decoder__1/pos_emb_1_1/add}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_494157[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_494676]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node transformer_1/decoder__1/pos_emb_1_1/add defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,50,512] vs. [1,100,512]\n\t [[{{node transformer_1/decoder__1/pos_emb_1_1/add}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_494157[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_494676]","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"# Get the vocabulary size\nvocab_size = sp_urdu.get_piece_size()\n\n# Iterate through the vocabulary and print each token\nfor i in range(vocab_size):\n    print(sp_urdu.id_to_piece(i))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LSTM_Translation_Model(tf.keras.Model):\n    def __init__(self, vocab_size_input, vocab_size_output, embedding_dim, lstm_units):\n        super(LSTM_Translation_Model, self).__init__()\n\n        # Encoder: Input Embedding -> LSTM -> Encoder Hidden State\n        self.encoder_embedding = tf.keras.layers.Embedding(vocab_size_input, embedding_dim)\n        self.encoder_lstm = tf.keras.layers.LSTM(lstm_units, return_state=True)\n\n        # Decoder: Output Embedding -> LSTM -> Dense (Softmax)\n        self.decoder_embedding = tf.keras.layers.Embedding(vocab_size_output, embedding_dim)\n        self.decoder_lstm = tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True)\n        self.decoder_dense = tf.keras.layers.Dense(vocab_size_output, activation='softmax')\n\n    def call(self, inputs):\n        encoder_input, decoder_input = inputs  # Unpack the tuple\n        \n        # Encoder\n        encoder_embedded = self.encoder_embedding(encoder_input)\n        encoder_output, state_h, state_c = self.encoder_lstm(encoder_embedded)\n\n        # Decoder\n        decoder_embedded = self.decoder_embedding(decoder_input)\n        decoder_output, _, _ = self.decoder_lstm(decoder_embedded, initial_state=[state_h, state_c])\n        decoder_output = self.decoder_dense(decoder_output)\n\n        return decoder_output\n\n# Parameters\nembedding_dim = 512\nlstm_units = 512\nvocab_size_input = eng_vocab_size  # Replace with your English vocab size\nvocab_size_output = urdu_vocab_size  # Replace with your Urdu vocab size\n\n# Initialize the model\nlstm_translation_model = LSTM_Translation_Model(vocab_size_input, vocab_size_output, embedding_dim, lstm_units)\n\n# Compile the model\nlstm_translation_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nlstm_h=lstm_translation_model.fit(train_dataset, validation_data=val_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T19:27:53.231260Z","iopub.execute_input":"2024-11-16T19:27:53.231966Z","iopub.status.idle":"2024-11-16T19:29:09.217347Z","shell.execute_reply.started":"2024-11-16T19:27:53.231925Z","shell.execute_reply":"2024-11-16T19:29:09.216437Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.6200 - loss: 3.1644 - val_accuracy: 0.7887 - val_loss: 1.5272\nEpoch 2/5\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8339 - loss: 1.2321 - val_accuracy: 0.8963 - val_loss: 0.8346\nEpoch 3/5\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9122 - loss: 0.7020 - val_accuracy: 0.9340 - val_loss: 0.5526\nEpoch 4/5\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9423 - loss: 0.4692 - val_accuracy: 0.9539 - val_loss: 0.3886\nEpoch 5/5\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9608 - loss: 0.3181 - val_accuracy: 0.9678 - val_loss: 0.2819\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import time\nimport numpy as np\nimport tensorflow as tf\nfrom memory_profiler import memory_usage\n\n# Function to calculate perplexity (lower is better)\ndef calculate_perplexity(model, dataset):\n    total_loss = 0\n    num_batches = 0\n    for batch in dataset:\n        inputs, targets = batch\n        # Make predictions\n        predictions = model(inputs, training=False)\n        loss = tf.keras.losses.sparse_categorical_crossentropy(targets, predictions, from_logits=True)\n        total_loss += tf.reduce_sum(loss)\n        num_batches += 1\n    avg_loss = total_loss / num_batches\n    perplexity = np.exp(avg_loss)\n    return perplexity\n\n# Measure training time for LSTM (2 epochs)\nstart_time_lstm = time.time()\nlstm_h = lstm_translation_model.fit(train_dataset, validation_data=val_dataset, epochs=2)\nend_time_lstm = time.time()\ntraining_time_lstm = end_time_lstm - start_time_lstm\n\n# Measure training time for Transformer (10 epochs)\nstart_time_transformer = time.time()\nhistory = transformer.fit(train_dataset, epochs=10, validation_data=val_dataset)\nend_time_transformer = time.time()\ntraining_time_transformer = end_time_transformer - start_time_transformer\n\n# Measure Memory Usage during Training for LSTM\ndef track_memory_usage_lstm():\n    def wrapper():\n        lstm_translation_model.fit(train_dataset, validation_data=val_dataset, epochs=2)\n    mem_usage_lstm = memory_usage(wrapper)\n    return max(mem_usage_lstm)\n\nmemory_usage_lstm = track_memory_usage_lstm()\n\n# Measure Memory Usage during Training for Transformer\ndef track_memory_usage_transformer():\n    def wrapper():\n        transformer.fit(train_dataset, epochs=10, validation_data=val_dataset)\n    mem_usage_transformer = memory_usage(wrapper)\n    return max(mem_usage_transformer)\n\nmemory_usage_transformer = track_memory_usage_transformer()\n\n# Measure Inference Speed for LSTM\ndef inference_speed_lstm(model, val_dataset):\n    start_time = time.time()\n    for batch in val_dataset.take(10):  # Taking a subset of validation data for inference\n        inputs, _ = batch\n        model(inputs, training=False)\n    end_time = time.time()\n    return (end_time - start_time) / 10  # Average time per batch\n\ninference_time_lstm = inference_speed_lstm(lstm_translation_model, val_dataset)\n\n# Measure Inference Speed for Transformer\ndef inference_speed_transformer(model, val_dataset):\n    start_time = time.time()\n    for batch in val_dataset.take(10):  # Taking a subset of validation data for inference\n        inputs, _ = batch\n        model(inputs, training=False)\n    end_time = time.time()\n    return (end_time - start_time) / 10  # Average time per batch\n\ninference_time_transformer = inference_speed_transformer(transformer, val_dataset)\n\n# Calculate Perplexity for LSTM Model\nperplexity_lstm = calculate_perplexity(lstm_translation_model, val_dataset)\n\n# Calculate Perplexity for Transformer Model\nperplexity_transformer = calculate_perplexity(transformer, val_dataset)\n\n# Print out the comparison results\nprint(f\"LSTM Training Time (2 epochs): {training_time_lstm:.2f} seconds\")\nprint(f\"Transformer Training Time (10 epochs): {training_time_transformer:.2f} seconds\")\nprint(f\"LSTM Memory Usage: {memory_usage_lstm:.2f} MB\")\nprint(f\"Transformer Memory Usage: {memory_usage_transformer:.2f} MB\")\nprint(f\"LSTM Inference Speed: {inference_time_lstm:.4f} seconds per batch\")\nprint(f\"Transformer Inference Speed: {inference_time_transformer:.4f} seconds per batch\")\nprint(f\"LSTM Perplexity: {perplexity_lstm:.2f}\")\nprint(f\"Transformer Perplexity: {perplexity_transformer:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T19:32:18.325059Z","iopub.execute_input":"2024-11-16T19:32:18.325808Z","iopub.status.idle":"2024-11-16T19:40:45.105637Z","shell.execute_reply.started":"2024-11-16T19:32:18.325767Z","shell.execute_reply":"2024-11-16T19:40:45.104459Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9722 - loss: 0.2287 - val_accuracy: 0.9767 - val_loss: 0.2121\nEpoch 2/2\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9810 - loss: 0.1575 - val_accuracy: 0.9824 - val_loss: 0.1667\nEpoch 1/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0293 - masked_accuracy: 0.1563 - val_loss: 5.4986 - val_masked_accuracy: 0.1452\nEpoch 2/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0123 - masked_accuracy: 0.1590 - val_loss: 5.5056 - val_masked_accuracy: 0.1461\nEpoch 3/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0266 - masked_accuracy: 0.1563 - val_loss: 5.5055 - val_masked_accuracy: 0.1429\nEpoch 4/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0005 - masked_accuracy: 0.1600 - val_loss: 5.5082 - val_masked_accuracy: 0.1451\nEpoch 5/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0174 - masked_accuracy: 0.1592 - val_loss: 5.5023 - val_masked_accuracy: 0.1425\nEpoch 6/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 5.0123 - masked_accuracy: 0.1590 - val_loss: 5.5002 - val_masked_accuracy: 0.1451\nEpoch 7/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 5.0007 - masked_accuracy: 0.1587 - val_loss: 5.5054 - val_masked_accuracy: 0.1469\nEpoch 8/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9894 - masked_accuracy: 0.1595 - val_loss: 5.4949 - val_masked_accuracy: 0.1452\nEpoch 9/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9942 - masked_accuracy: 0.1587 - val_loss: 5.5106 - val_masked_accuracy: 0.1470\nEpoch 10/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9746 - masked_accuracy: 0.1624 - val_loss: 5.5022 - val_masked_accuracy: 0.1429\nEpoch 1/2\n\u001b[1m  1/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.9844 - loss: 0.1183","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9864 - loss: 0.1114 - val_accuracy: 0.9862 - val_loss: 0.1352\nEpoch 2/2\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9909 - loss: 0.0753 - val_accuracy: 0.9886 - val_loss: 0.1141\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9833 - masked_accuracy: 0.1602 - val_loss: 5.5024 - val_masked_accuracy: 0.1457\nEpoch 2/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9773 - masked_accuracy: 0.1595 - val_loss: 5.4998 - val_masked_accuracy: 0.1461\nEpoch 3/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9670 - masked_accuracy: 0.1611 - val_loss: 5.5036 - val_masked_accuracy: 0.1465\nEpoch 4/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 4.9805 - masked_accuracy: 0.1595 - val_loss: 5.4906 - val_masked_accuracy: 0.1481\nEpoch 5/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - loss: 4.9642 - masked_accuracy: 0.1604 - val_loss: 5.5035 - val_masked_accuracy: 0.1462\nEpoch 6/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 4.9584 - masked_accuracy: 0.1618 - val_loss: 5.5078 - val_masked_accuracy: 0.1471\nEpoch 7/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - loss: 4.9514 - masked_accuracy: 0.1635 - val_loss: 5.5016 - val_masked_accuracy: 0.1491\nEpoch 8/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 119ms/step - loss: 4.9528 - masked_accuracy: 0.1612 - val_loss: 5.5030 - val_masked_accuracy: 0.1477\nEpoch 9/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 119ms/step - loss: 4.9476 - masked_accuracy: 0.1629 - val_loss: 5.5005 - val_masked_accuracy: 0.1454\nEpoch 10/10\n\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 4.9470 - masked_accuracy: 0.1621 - val_loss: 5.5097 - val_masked_accuracy: 0.1463\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/3151321084.py:18: RuntimeWarning: overflow encountered in exp\n  perplexity = np.exp(avg_loss)\n","output_type":"stream"},{"name":"stdout","text":"LSTM Training Time (2 epochs): 28.75 seconds\nTransformer Training Time (10 epochs): 220.62 seconds\nLSTM Memory Usage: 3872.61 MB\nTransformer Memory Usage: 3876.73 MB\nLSTM Inference Speed: 0.0402 seconds per batch\nTransformer Inference Speed: 0.3738 seconds per batch\nLSTM Perplexity: inf\nTransformer Perplexity: inf\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}